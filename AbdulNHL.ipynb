{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37c53071-0cd0-4b38-90e3-ae7daa7b24b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abdul\n"
     ]
    }
   ],
   "source": [
    "print(\"Abdul\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a98572a2-4fb2-4af8-9fde-f0a0ff26d315",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (1555924590.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    def id_to_fruit(fruit_id: int, fruits: Set[str]) -> str:\u001b[0m\n\u001b[0m                                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "def id_to_fruit(fruit_id: int, fruits: Set[str]) -> str:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18aaf3de-7f83-46f8-b043-283a11bf170b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mid_to_fruit\u001b[39m(fruit_id: \u001b[38;5;28mint\u001b[39m, fruits: \u001b[43mSet\u001b[49m[\u001b[38;5;28mstr\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m    This method returns the fruit name by getting the string at a specific index of the set.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;03m    >>> name4 = id_to_fruit(4, {\"apple\", \"orange\", \"melon\", \"kiwi\", \"strawberry\"})\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Set' is not defined"
     ]
    }
   ],
   "source": [
    "def id_to_fruit(fruit_id: int, fruits: Set[str]) -> str:\n",
    "    \"\"\"\n",
    "    This method returns the fruit name by getting the string at a specific index of the set.\n",
    "\n",
    "    :param fruit_id: The id of the fruit to get\n",
    "    :param fruits: The set of fruits to choose the id from\n",
    "    :return: The string corrosponding to the index ``fruit_id``\n",
    "\n",
    "    **This method is part of a series of debugging exercises.**\n",
    "    **Each Python method of this series contains bug that needs to be found.**\n",
    "\n",
    "    | ``1   It does not print the fruit at the correct index, why is the returned result wrong?``\n",
    "    | ``2   How could this be fixed?``\n",
    "\n",
    "    This example demonstrates the issue:\n",
    "    name1, name3 and name4 are expected to correspond to the strings at the indices 1, 3, and 4:\n",
    "    'orange', 'kiwi' and 'strawberry'..\n",
    "\n",
    "    >>> name1 = id_to_fruit(1, {\"apple\", \"orange\", \"melon\", \"kiwi\", \"strawberry\"})\n",
    "    >>> name3 = id_to_fruit(3, {\"apple\", \"orange\", \"melon\", \"kiwi\", \"strawberry\"})\n",
    "    >>> name4 = id_to_fruit(4, {\"apple\", \"orange\", \"melon\", \"kiwi\", \"strawberry\"})\n",
    "    \"\"\"\n",
    "    idx = 0\n",
    "    for fruit in fruits:\n",
    "        if fruit_id == idx:\n",
    "            return fruit\n",
    "        idx += 1\n",
    "    raise RuntimeError(f\"Fruit with id {fruit_id} does not exist\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ecae63a-ec2b-4033-ae6f-2ac9fbabf3ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'id_to_fruit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid fruit_id: Out of range\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n\u001b[0;32m----> 8\u001b[0m name1 \u001b[38;5;241m=\u001b[39m \u001b[43mid_to_fruit\u001b[49m(\u001b[38;5;241m1\u001b[39m, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapple\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morange\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmelon\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkiwi\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrawberry\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[1;32m      9\u001b[0m name3 \u001b[38;5;241m=\u001b[39m id_to_fruit(\u001b[38;5;241m3\u001b[39m, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapple\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morange\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmelon\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkiwi\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrawberry\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[1;32m     10\u001b[0m name4 \u001b[38;5;241m=\u001b[39m id_to_fruit(\u001b[38;5;241m4\u001b[39m, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapple\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morange\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmelon\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkiwi\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrawberry\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n",
      "\u001b[0;31mNameError\u001b[0m: name 'id_to_fruit' is not defined"
     ]
    }
   ],
   "source": [
    "def get_fruit_name(fruit_id: int, fruits: set[str]) -> str:\n",
    "    \n",
    "    fruit_list = sorted(fruits) \n",
    "    if 0 <= fruit_id < len(fruit_list):  \n",
    "        return fruit_list[fruit_id]\n",
    "    else:\n",
    "        raise IndexError(\"Invalid fruit_id: Out of range\") \n",
    "name1 = id_to_fruit(1, {\"apple\", \"orange\", \"melon\", \"kiwi\", \"strawberry\"})\n",
    "name3 = id_to_fruit(3, {\"apple\", \"orange\", \"melon\", \"kiwi\", \"strawberry\"})\n",
    "name4 = id_to_fruit(4, {\"apple\", \"orange\", \"melon\", \"kiwi\", \"strawberry\"})\n",
    "\n",
    "print(name1) \n",
    "print(name3)  \n",
    "print(name4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79426e1a-2587-4436-9737-e16707466108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kiwi\n",
      "orange\n",
      "strawberry\n"
     ]
    }
   ],
   "source": [
    "from typing import Set \n",
    "\n",
    "def get_fruit_name(fruit_id: int, fruits: Set[str]) -> str:\n",
    "    fruit_list = sorted(fruits)  \n",
    "    if 0 <= fruit_id < len(fruit_list):  \n",
    "        return fruit_list[fruit_id]\n",
    "    else:\n",
    "        raise IndexError(\"Invalid fruit_id: Out of range\")\n",
    "fruits_set = {\"apple\", \"orange\", \"melon\", \"kiwi\", \"strawberry\"}\n",
    "name1 = get_fruit_name(1, fruits_set)\n",
    "name3 = get_fruit_name(3, fruits_set)\n",
    "name4 = get_fruit_name(4, fruits_set)\n",
    "\n",
    "print(name1)\n",
    "print(name3)  \n",
    "print(name4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6645b5da-2eb1-45ad-b062-6064ccd487f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mswap\u001b[39m(coords: \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m      3\u001b[0m             [[x11, y11, x12, y12, classid1],\n\u001b[1;32m      4\u001b[0m              [x21, y21, x22, y22, classid2],\n\u001b[1;32m      5\u001b[0m              [xn1, yn1, xn2, yn2, classid3]]\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "def swap(coords: np.ndarray):\n",
    "\n",
    "            [[x11, y11, x12, y12, classid1],\n",
    "             [x21, y21, x22, y22, classid2],\n",
    "             [xn1, yn1, xn2, yn2, classid3]]\n",
    "\n",
    "    \n",
    "\n",
    "import numpy as np\n",
    "coords = np.array([[10, 5, 15, 6, 0],\n",
    "                   [11, 3, 13, 6, 0],\n",
    "                   [5, 3, 13, 6, 1],\n",
    "                   [4, 4, 13, 6, 1],\n",
    "                   [6, 5, 13, 16, 1]])\n",
    "swapped_coords = swap(coords)\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "756b3508-6c34-4798-8cb0-112fde50b763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5 10  6 15  0]\n",
      " [ 3 11  6 13  0]\n",
      " [ 3  5  6 13  1]\n",
      " [ 4  4  6 13  1]\n",
      " [ 5  6 16 13  1]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def swap(coords: np.ndarray):\n",
    "    coords = coords.copy() \n",
    "    coords[:, [0, 1, 2, 3]] = coords[:, [1, 0, 3, 2]] \n",
    "    return coords\n",
    "\n",
    "coords = np.array([[10, 5, 15, 6, 0],\n",
    "                   [11, 3, 13, 6, 0],\n",
    "                   [5, 3, 13, 6, 1],\n",
    "                   [4, 4, 13, 6, 1],\n",
    "                   [6, 5, 13, 16, 1]])\n",
    "\n",
    "swapped_coords = swap(coords)\n",
    "print(swapped_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4a6777d-1d13-482d-b7c6-36643df61e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can copy this code to your personal pipeline project or execute it here.\n",
    "def plot_data(csv_file_path: str):\n",
    "\n",
    "    results = []\n",
    "    with open(csv_file_path) as result_csv:\n",
    "        csv_reader = csv.reader(result_csv, delimiter=',')\n",
    "        next(csv_reader)\n",
    "        for row in csv_reader:\n",
    "            results.append(row)\n",
    "        results = np.stack(results)\n",
    "\n",
    "    # plot precision-recall curve\n",
    "    plt.plot(results[:, 1], results[:, 0])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4206c5f9-afcb-488f-ad87-13d5834e8cbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArMAAAIhCAYAAABdSTJTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABoA0lEQVR4nO3dd3hUVf7H8c+kF0hQQgkkJFQBkRakuYCgwNI1IlXpKuIuzbKiroINZZVF/VFcBbKiIkiTEoWIlChIMwgCKkIwlAAC0lvK/f1xdwaGJJCESW5m8n49z30mc+fcO9+ZA/rh5NxzbYZhGAIAAADckJfVBQAAAAD5RZgFAACA2yLMAgAAwG0RZgEAAOC2CLMAAABwW4RZAAAAuC3CLAAAANwWYRYAAABuizALAAAAt0WYBVBg4uLiZLPZHJuPj48iIiI0cOBAHTx4sNDrGTBggKKjo/N0zL59+2Sz2RQXF1cgNd3IgAEDnL5DPz8/Va1aVU899ZROnz5tSU1Xy+77sff7vn37cnWObdu2aeDAgapcubICAgJUokQJNWzYUBMmTNCJEycKpnAAHsPH6gIAeL6ZM2eqZs2aunDhgtauXavx48drzZo12r59u4KDgwutjn/+858aMWJEno4JDw/X+vXrVbVq1QKq6sYCAwP1zTffSJJOnjypefPm6e2339a2bdu0YsUKy+pyhQ8++EDDhg3Tbbfdpqefflq1a9dWWlqaNm/erGnTpmn9+vVauHCh1WUCKMIIswAKXJ06ddSoUSNJUuvWrZWRkaFXXnlFixYtUt++fbM95vz58woKCnJpHfkJpP7+/mratKlL68grLy8vpxr++te/au/evUpISFBycrIqV65sYXX5t379ej3++ONq27atFi1aJH9/f8drbdu21ZNPPqmvvvrKJe914cIFBQQEyGazueR8AIoOphkAKHT2YPb7779LMn+VXqJECW3fvl3t2rVTyZIldc8990iSLl++rFdffVU1a9aUv7+/ypQpo4EDB+qPP/7Ict5PP/1UzZo1U4kSJVSiRAnVr19f06dPd7ye3TSDzz//XE2aNFFoaKiCgoJUpUoVDRo0yPF6TtMMvv32W91zzz0qWbKkgoKC1Lx5cy1btsypjf3X7atWrdLjjz+usLAwlS5dWrGxsTp06FC+vz9Jjn8cHDlyxGn/nDlz1KxZMwUHB6tEiRJq3769kpKSshy/YcMGdenSRaVLl1ZAQICqVq2qkSNHOl7/7bffNHDgQFWvXl1BQUGqWLGiunTpou3bt99U3Vd7/fXXZbPZ9J///McpyNr5+fmpa9eujuc2m01jx47N0i46OloDBgxwPLd/7ytWrNCgQYNUpkwZBQUFac6cObLZbFq5cmWWc0ydOlU2m03btm1z7Nu8ebO6du2qW2+9VQEBAWrQoIHmzp17cx8agMsRZgEUut9++02SVKZMGce+y5cvq2vXrmrTpo2++OILjRs3TpmZmerWrZveeOMN9enTR8uWLdMbb7yhhIQE3X333bpw4YLj+BdffFF9+/ZVhQoVFBcXp4ULF6p///6OwJyd9evXq2fPnqpSpYo+++wzLVu2TC+++KLS09OvW/+aNWvUpk0bnTp1StOnT9fs2bNVsmRJdenSRXPmzMnSfsiQIfL19dWnn36qCRMmaPXq1XrooYfy+rU5SU5Olo+Pj6pUqeLY9/rrr6t3796qXbu25s6dq1mzZunMmTNq0aKFdu7c6Wi3fPlytWjRQikpKZo4caK+/PJLvfDCC07B+NChQypdurTeeOMNffXVV5o8ebJ8fHzUpEkT/fLLLzdVuyRlZGTom2++UUxMjCIjI2/6fNkZNGiQfH19NWvWLM2bN0/333+/ypYtq5kzZ2ZpGxcXp4YNG6pu3bqSpFWrVumuu+7SyZMnNW3aNH3xxReqX7++evbsadn8aQA5MACggMycOdOQZHz//fdGWlqacebMGWPp0qVGmTJljJIlSxqHDx82DMMw+vfvb0gyZsyY4XT87NmzDUnG/PnznfZv2rTJkGRMmTLFMAzD2Lt3r+Ht7W307dv3uvX079/fiIqKcjx/6623DEnGyZMnczwmOTnZkGTMnDnTsa9p06ZG2bJljTNnzjj2paenG3Xq1DEiIiKMzMxMp88/bNgwp3NOmDDBkGSkpqZet157zcHBwUZaWpqRlpZmHDt2zJg6darh5eVlPPfcc452KSkpho+Pj/H3v//d6fgzZ84Y5cuXN3r06OHYV7VqVaNq1arGhQsXbvj+V3++y5cvG9WrVzdGjRrl2J/d92P/3MnJyTme7/Dhw4Yko1evXrmuQZLx0ksvZdkfFRVl9O/fP8v79+vXL0vb0aNHG4GBgU59vnPnTkOS8d577zn21axZ02jQoIGRlpbmdHznzp2N8PBwIyMjI9d1AyhYjMwCKHBNmzaVr6+vSpYsqc6dO6t8+fL68ssvVa5cOad2DzzwgNPzpUuXqlSpUurSpYvS09MdW/369VW+fHmtXr1akpSQkKCMjAw98cQTearrzjvvlCT16NFDc+fOzdUKC+fOndOGDRvUvXt3lShRwrHf29tbDz/8sA4cOJBl5PLqX5VLcoz+2UeNMzMznT5fRkZGlvf09fWVr6+vwsLC9Pjjj6tnz5567bXXHG2WL1+u9PR09evXz+lcAQEBatWqleO7+vXXX7Vnzx4NHjxYAQEBOX7O9PR0vf7666pdu7b8/Pzk4+MjPz8/7d69W7t27brh91QUXPvnSTJHay9cuOA0gj5z5kz5+/urT58+kszfHPz888+O+dxXf58dO3ZUamqqS0anAbgGYRZAgfvoo4+0adMmJSUl6dChQ9q2bZvuuusupzZBQUEKCQlx2nfkyBGdPHlSfn5+jjBn3w4fPqxjx45JkmP+bERERJ7qatmypRYtWuQIgREREapTp45mz56d4zF//vmnDMNQeHh4ltcqVKggSTp+/LjT/tKlSzs9t88PtU+TePnll50+27UXqgUGBmrTpk3atGmTlixZorvvvluzZ8/WG2+84WhjnyJw5513Zvmu5syZk+fvavTo0frnP/+p++67T0uWLNGGDRu0adMm1atXz2l6R36FhYUpKChIycnJN32unGTXR7fffrvuvPNOx1SDjIwMffzxx+rWrZtuvfVWSVe+y6eeeirLdzls2DBJcnyfAKzHagYAClytWrUcFyzlJLurzO0XTOV0RXvJkiUlXZl7e+DAgTzPv+zWrZu6deumS5cu6fvvv9f48ePVp08fRUdHq1mzZlna33LLLfLy8lJqamqW1+wXdYWFheWphkcffVSdO3d2PL/2YigvLy+n769t27aKiYnRuHHj1LdvX0VGRjrec968eYqKisrxva7+rq7n448/Vr9+/fT666877T927JhKlSqVq891Pd7e3rrnnnv05Zdf6sCBA7n6h4i/v78uXbqUZf+1/3iwy2nlgoEDB2rYsGHatWuX9u7dq9TUVA0cONDxuv27HDNmjGJjY7M9x2233XbDegEUDsIsgCKrc+fO+uyzz5SRkaEmTZrk2K5du3by9vbW1KlTsw2gueHv769WrVqpVKlSWr58uZKSkrI9V3BwsJo0aaIFCxborbfeUmBgoCRzqsDHH3+siIgI1ahRI0/vXaFCBceobm5rnTx5su6++269+uqrev/999W+fXv5+Phoz5492f563a5GjRqqWrWqZsyYodGjR2e7ioBkBsFrX1u2bJkOHjyoatWq5brW6xkzZozi4+P1yCOP6IsvvpCfn5/T62lpafrqq6/UpUsXSeaqBVevNiBJ33zzjc6ePZun9+3du7dGjx6tuLg47d27VxUrVlS7du0cr992222qXr26fvzxxyxhHkDRQ5gFUGT16tVLn3zyiTp27KgRI0aocePG8vX11YEDB7Rq1Sp169ZN999/v6Kjo/Xcc8/plVde0YULF9S7d2+FhoZq586dOnbsmMaNG5ft+V988UUdOHBA99xzjyIiInTy5Em988478vX1VatWrXKsa/z48Wrbtq1at26tp556Sn5+fpoyZYp++uknzZ49u1DWMm3VqpU6duyomTNn6tlnn1XlypX18ssv6/nnn9fevXv117/+VbfccouOHDmijRs3Kjg42PE9TJ48WV26dFHTpk01atQoVapUSSkpKVq+fLk++eQTSeY/JOLi4lSzZk3VrVtXW7Zs0b/+9a88T+W4nmbNmmnq1KkaNmyYYmJi9Pjjj+v2229XWlqakpKS9J///Ed16tRxhNmHH35Y//znP/Xiiy+qVatW2rlzp/7v//5PoaGheXrfUqVK6f7771dcXJxOnjypp556Sl5ezrPu3n//fXXo0EHt27fXgAEDVLFiRZ04cUK7du3SDz/8oM8//9xl3wOAm2T1FWgAPJf9qvJNmzZdt539iv3spKWlGW+99ZZRr149IyAgwChRooRRs2ZN47HHHjN2797t1Pajjz4y7rzzTke7Bg0aOF1lf+1qBkuXLjU6dOhgVKxY0fDz8zPKli1rdOzY0UhMTHS0ye5qfcMwjMTERKNNmzZGcHCwERgYaDRt2tRYsmRJrj7/qlWrDEnGqlWrrvu93Oi72b59u+Hl5WUMHDjQsW/RokVG69atjZCQEMPf39+Iiooyunfvbnz99ddOx65fv97o0KGDERoaavj7+xtVq1Z1WqXgzz//NAYPHmyULVvWCAoKMv7yl78YiYmJRqtWrYxWrVpd9/vJzWoGV9u6davRv39/o1KlSoafn58RHBxsNGjQwHjxxReNo0ePOtpdunTJeOaZZ4zIyEgjMDDQaNWqlbF169YcVzO43p+7FStWGJIMScavv/6abZsff/zR6NGjh1G2bFnD19fXKF++vNGmTRtj2rRpufpcAAqHzTAMw7IkDQAAANwEVjMAAACA2yLMAgAAwG0RZgEAAOC2CLMAAABwW4RZAAAAuC3CLAAAANxWsbtpQmZmpg4dOqSSJUsWysLmAAAAyBvDMHTmzBlVqFAhy01NrlXswuyhQ4fyfO92AAAAFL79+/ff8M6DxS7MlixZUpL55YSEhLjknGlpaVqxYoXatWsnX19fl5wThY9+9Bz0pWegHz0D/egZCrsfT58+rcjISEduu55iF2btUwtCQkJcGmaDgoIUEhLCX1Q3Rj96DvrSM9CPnoF+9AxW9WNupoRyARgAAADcFmEWAAAAboswCwAAALdV7ObMAgBQGDIyMpSWlmZ1GZZLS0uTj4+PLl68qIyMDKvLQT4VRD/6+vrK29v7ps9DmAUAwMXOnj2rAwcOyDAMq0uxnGEYKl++vPbv38/67m6sIPrRZrMpIiJCJUqUuKnzEGYBAHChjIwMHThwQEFBQSpTpkyxD3CZmZk6e/asSpQoccPF71F0ubofDcPQH3/8oQMHDqh69eo3NUJLmAUAwIXS0tJkGIbKlCmjwMBAq8uxXGZmpi5fvqyAgADCrBsriH4sU6aM9u3bp7S0tJsKs/ypAgCgABT3EVngRlz1d4QwCwAAALdFmAUAAIDbIswCAFAEZWRIq1dLs2ebj566qlV0dLQmTZrk8raewGazadGiRZKkffv2yWazaevWrZbWVBQRZgEAKGIWLJCio6XWraU+fczH6Ghzf0EZMGCAbDabbDabfH19VaVKFT311FM6d+5cwb2ppE2bNunRRx91edubcffddzu+Cz8/P1WtWlVjxozRpUuXCvy9b9Zvv/2mgQMHKiIiQv7+/qpcubJ69+6tzZs3W11agSHMAgBQhCxYIHXvLh044Lz/4EFzf0EG2r/+9a9KTU3V3r179eqrr2rKlCl66qmnsm3rqhtClClTRkFBQS5ve7MeeeQRpaam6rffftOECRM0efJkjR07tlDeO782b96smJgY/frrr3r//fe1c+dOLVy4UDVr1tSTTz6Z7/NmZGQoMzPThZW6FmG2gBWXXxMBALJnGNK5c7nbTp+Whg83j8nuPJI0YoTZLjfny+s9G/z9/VW+fHlFRkaqT58+6tu3r+PX3GPHjlX9+vU1Y8YMValSRf7+/jIMQ6dOndKjjz6qsmXLKiQkRG3atNGPP/7odN74+Hg1btxYAQEBCgsLU2xsrOO1a6cOjB07VpUqVZK/v78qVKig4cOH59g2JSVF3bp1U4kSJRQSEqIePXroyJEjTueqX7++Zs2apejoaIWGhqpXr146c+bMDb+LoKAglS9fXpUqVdIDDzygtm3basWKFY7XDcPQhAkTVKVKFQUGBqpevXqaN2+e0zl27NihTp06KSQkRCVLllSLFi20Z88eSeYoc9u2bRUWFqbQ0FC1atVKP/zwww3ryolhGBowYICqV6+uxMREderUSVWrVlX9+vX10ksv6YsvvpAkrV69WjabTSdPnnQcu3XrVtlsNu3bt0+SFBcXp1KlSmnp0qWqXbu2/P399cEHH6h8+fJOx0nS8OHD1apVK8fzdevWqWXLlgoMDFRkZKSGDx9e4KP7hNkCZMWviQAARcv581KJErnbQkPNEdicGIY5YhsamrvznT9/c7UHBgY6jcD+9ttvmjt3rubPn++Yu9mpUycdPnxY8fHx2rJlixo2bKh77rlHJ06ckCQtW7ZM/fr1U8eOHZWUlKSVK1eqUaNG2b7fvHnz9O9//1vvv/++du/erUWLFumOO+7I4bswdN999+nEiRNas2aNEhIStGfPHvXs2dOp3Z49e7Ro0SItXbpUS5cu1Zo1a/TGG2/k6Xv48ccf9d1338nX19ex74UXXtDMmTM1depU7dixQ6NGjdJDDz2kNWvWSJIOHjyoli1bKiAgQN988422bNmiQYMGKT09XZJ05swZ9e/fX4mJifr+++9VvXp1dezYMVdBOztbt27Vjh079OSTT2a7DmypUqXydL7z589r/Pjx+vDDD7Vjxw499NBDCg0N1fz58x1tMjIyNHfuXPXt21eStH37drVv316xsbHatm2b5syZo2+//VZ/+9vf8vWZcs0oZk6dOmVIMk6dOuWyc16+fNlYtGiRcfnyZce++fMNw2YzDPM/PVc2m83c5s932dvDRbLrR7gn+tIzuGs/Xrhwwdi5c6dx4cIFwzAM4+zZrP8vKKzt7Nnc192/f3+jW7dujucbNmwwSpcubfTo0cMwDMN46aWXDF9fX+Po0aOONitXrjRCQkKMixcvOp2ratWqxvvvv28YhmE0a9bMePDBB42MjIxs3zcqKsr497//bRiGYbz99ttGjRo1cuzzq9uuWLHC8Pb2NlJSUhyv79ixw5BkbNy40VFzUFCQcfr0aUebp59+2mjSpMl1v4tWrVoZvr6+RnBwsOHn52dIMry8vIx58+YZhmEYZ8+eNQICAox169Y5HTd48GCjd+/ehmEYxpgxY4zKlSvn+s9venq6UbJkSWPJkiWOfZKMhQsXGoZhGMnJyYYkIykpKdvj58yZY0gyfvjhh+u+z6pVqwxJxp9//unYl5SUZEgykpOTDcMwjJkzZxqSjK1btzraZGRkGI899pjRpk0bx77ly5cbfn5+xokTJwzDMIyHH37YePTRR53eLzEx0fDy8nL8fbjatX9XrpaXvMbIbAHIyDB/DXS9XxONHMmUAwAoDoKCpLNnc7fFx+funPHxuTtfXqeXLl26VCVKlFBAQICaNWumli1b6r333nO8HhUVpTJlyjieb9myRWfPnlXp0qVVokQJx5acnOz4dfrWrVudfg19PQ8++KAuXLigKlWq6JFHHtHChQsdI5nX2rVrlyIjIxUZGenYV7t2bZUqVUq7du1y7IuOjlbJkiUdz8PDw3X06FFJ0ieffOJUd2JioqNd3759tXXrVq1fv149evTQoEGD9MADD0iSdu7cqYsXL6pt27ZOx3/00UdOn7tFixZOo7lXO3r0qIYOHaoaNWooNDRUoaGhOnv2rFJSUnL1XV3L+F/AcNWNCPz8/FS3bl2nfQ8++KBWr16tQ4cOSTK/v44dO+qWW26RZP55iIuLc/pO2rdvr8zMTCUnJ7ukruxwO9sCkJiYdeL+1QxD2r9fWrJEuu++QisLAGABm00KDs5d23btpIgIc6pBdgMiNpv5ert20k3c/TNHrVu31tSpU+Xr66sKFSpkCWLB13yQzMxMhYeHa/Xq1VnOZf+1dl5u6RsZGalffvlFCQkJ+vrrrzVs2DD961//0po1a7LUYhhGtsHt2v3XHmez2RwXM3Xt2lVNmjRxvFaxYkXHz6GhoapWrZok6eOPP9btt9+u6dOna/DgwY7jly1b5nSMZM47zs3nHjBggP744w9NmjRJUVFR8vf3V7NmzXT58uXrHpeTGjVqSDJDfv369XNsZ5+CYFz1Byy7i/kCAwOzfL8xMTGqWrWqPvvsMz3++ONauHChZs6c6Xg9MzNTjz32mNM8Z7tKlSrl6fPkBWG2AKSm5q7d/febc2ibNJEaNzYfGzTI+7+kAQCewdtbeucdc9UCm8050NpzxaRJBRNkJTOs2gNcbjRs2FCHDx+Wj4+PoqOjs21Tt25drVmzRo8//niuzhkYGKiuXbuqa9eueuKJJ1SzZk1t375dDRs2dGpXu3ZtpaSkaP/+/Y7R2Z07d+rUqVOqVatWrt6rZMmSTqO2OfH19dVzzz2nMWPGqHfv3o6LolJSUnIcda5bt67++9//Ki0tLdvR2cTERE2ZMkUdO3aUJO3fv1/Hjh3LVd3ZqV+/vmrXrq23335bPXv2zDJv9uTJkypVqpRjZD01NdUxopqXtWt79+6tTz75RBEREfLy8lKnTp0crzVs2FA7duzI058hV2CaQQEID8992337pDlzpCeflP7yFykkRGrYUHr8cWnmTGnnTqkIr4YBAHCx2Fhp3jzpmgE/RUSY+69aCMBy9957r5o1a6b77rtPy5cv1759+7Ru3Tq98MILjnVN//nPf2r+/PkaO3asdu3ape3bt2vChAnZni8uLk7Tp0/XTz/9pL1792rWrFkKDAxUVFRUtu9dt25d9e3bVz/88IM2btyofv36qVWrVjleYHYz+vTpI5vNpilTpqhkyZJ66qmnNGrUKP33v//Vnj17lJSUpMmTJ+u///2vJOlvf/ubTp8+rV69emnz5s3avXu3Zs2apV9++UWSVK1aNc2aNUu7du3Shg0b1Ldv3zyNYl/LZrNp5syZ+vXXX9WyZUvFx8dr79692rZtm1577TV169bN8b6RkZEaO3asfv31Vy1btkxvv/12nr6HH374Qa+99pq6d++ugIAAx2v/+Mc/tH79ej3xxBPaunWrdu/ercWLF+vvf/97vj9XbhBmC0CLFuZ/dHKatmKzSZGR0vHj0tdfS6+/LnXrJpUvb86jTUqSpk2TBg2Sbr9dKlVKuuceacwYadEi6X9TVQAAHio21hzsWLVK+vRT8zE5uWgFWckMUPHx8WrZsqUGDRqkGjVqqFevXtq3b5/KlSsnybwBQVxcnJYsWaL69eurTZs22rBhQ7bnK1WqlD744APdddddqlu3rlauXKklS5aodOnS2b73okWLdMstt6hly5a69957VaVKFc2ZM6dAPqufn5/+9re/acKECTp79qxeeeUVvfjiixo/frxq1aql9u3ba8mSJapcubIkqXTp0vrmm2909uxZtWrVSjExMfrggw8co7QzZszQn3/+qQYNGujhhx/W8OHDVbZs2ZuqsXHjxtq8ebOqVq2qRx55RLVq1VLXrl21Y8cOx5Jmvr6+mj17tn7++WfVq1dPb775pl599dVcv0f16tV15513atu2bY5VDOzso/C7d+9WixYt1KBBA/3zn/9UeF5G+fLBZhjZzcrxXKdPn1ZoaKhOnTqlkJAQl5wzLS1N8fHx6tixo+MPqX3Rayn7XxNl969r+5IrGzdKGzaYj5s3m2sFXisi4srUhMaNpUaNzGVYkH/Z9SPcE33pGdy1Hy9evKjk5GRVrlzZadSquMrMzNTp06cVEhKS7ZJRcA8F0Y/X+7uSl7zGnNkCYv810YgRzheDRUSY852y+9e1fcQ2MlL63wWTSk+Xdu0yw6094P70k3nOAweurFnr5SXVrm2GW3vAvf12yYceBgAAHoyoU4BiY83pA4mJ5kVh4eHmFIS8TNz38ZHuuMPchgwx9509K/3ww5Vwu2GDuTrCTz+Z2/TpZrugICkmxvkCs8jInKc/AAAAuBvCbAHz9pbuvtu15yxRQmrZ0tzsUlPNYGsPt5s2mbc7TEw0N7ty5ZzDbaNG5pxcAAAAd0SY9RDh4eYo8P8uVlRmpvTLL86jt9u2SUeOSIsXm5tdzZrOAfeOOyQ/P2s+BwAAQF4QZj2Ul5dUq5a5DRhg7rtwwVwp4eoLzPbulX7+2dz+t5qI/P3N5cGuvsCsShWmJwBAXhSz66uBPHPV3xHCbDESGCg1b25udn/84Tw9YeNG6c8/pfXrzc2udGnncNu4sbkPAODM+38XRly+fPmm1g0FPJ39bmfeN3kXEMJsMVemjNSpk7lJ5vJgv/3mHG6Tksw1cb/80tzsqlVzDrj160usQgOguPPx8VFQUJD++OMP+fr6FvvlqDIzM3X58mVdvHix2H8X7szV/ZiZmak//vhDQUFB8rnJpZcIs3Bis0nVq5ubfS3kS5fM+bZXz7/99Vcz9P72m7mgtyT5+kr16jnPv61e3ZzyAADFhc1mU3h4uJKTk/X7779bXY7lDMPQhQsXFBgYKBvz1dxWQfSjl5eXKlWqdNPnI8zihvz9pTvvNDe7P/80V0y4OuD+8Yd5k4fNm6XJk812pUqZx109gvu/m8IAgMfy8/NT9erVHb9GLc7S0tK0du1atWzZ0q1ufgFnBdGPfn5+LhnlJcwiX265RWrXztwkc3rC7787h9stW6STJ6WEBHOzi4pyHr1t2NBcExcAPImXlxd3AJM5HzI9PV0BAQGEWTdWlPuRMAuXsNmk6Ghz69nT3JeWZt7EwR5uN2ww72b2++/mNneu2c7b21wO7OrR21q18nZzCQAAUDwRZlFgfH2lBg3M7bHHzH2nT5vTEK4OuKmp0tat5vaf/5jtSpQwb+hw9e15K1a06pMAAICiijCLQhUSIrVpY252Bw44r56waZN5y97Vq83NrmJF59HbRo2kkiUL+xMAAICihDALy0VEmFtsrPk8I0PaudM54G7fLh08KC1caG6SObWhdm3n+bd16kg3ucIHAABwI/xvH0WOfQ7tHXdIgweb+86dk374wfkCs5QUaccOc5sxw2wXGCjFxDgH3EqVuHsZAACeijALtxAcLLVoYW52hw87j95u3GjOyf32W3OzK1vWOdzeeae5ZBgAAHB/hFm4rfLlpa5dzU2SMjPNmzlcPXr744/S0aPSkiXmZnfbbc7zb+vVY/QWAAB3RJiFx/DykmrWNLf+/c19Fy+at+O9evWEvXulX34xt1mzzHb+/lL9+t4qU6aOTp2yqXlzqWpVAi4AAEUdYRYeLSBAatbM3OyOHbsyLcE+invihLRhg5ekqlq61Gx3663Oo7eNG0thYZZ8DAAAkAPCLIqdsDCpY0dzk8y7l+3ZI61bl67PP/9dR49W1tatXjpxQvrqK3Ozq1LFef5t/frmRWcAAMAahFkUezabVK2aFBVlKDT0J3XsWEmG4aUff3Qevf3lF3OKwt690uzZ5rE+PuZ8W3u4bdJEqlHDnPIAAAAKHmEWyIafn7nqwZ13Sk88Ye7780/z7mVXX2B29Ki0ZYu5TZ1qtgsNNY+7eopC+fLWfRYAADwZYRbIpVtukdq2NTfJnJ6QkuIcbrdskU6dkr7+2tzsKlVyDrcxMeZyYwAA4OYQZoF8stmkqChz69HD3JeWZt7E4eqAu3OnGXpTUqR588x2Xl7m3crsUxMaNzbvZubtbd3nAQDAHRFmARfy9TUvCqtfX3rsMXPfmTPm9ISrlwc7dEjats3cPvjAbBccLDVq5HyBWcWKLA8GAMD1EGaBAlaypNS6tbnZHTzoPHq7ebN09qy0Zo252YWHO4fbRo2kkJDC/wwAABRVhFnAAhUrSrGx5iZJGRnSrl3Oqyds3y6lpkqLFpmbZI7S1qrlvHpCnTrmiDAAAMURYRYoAry9zVBap440aJC579w58+5l9qkJGzdKv/9uzsHduVOKizPbBQZKDRs6X2AWHc30BABA8UCYBYqo4GDpL38xN7sjR5xHbzduNFdP+O47c7MrUybr3ctuuaXwPwMAAAWNMAu4kXLlpC5dzE2SMjOl3bud59/++KP0xx/SsmXmZle9uvPqCfXqSf7+1nwOAABchTALuDEvL+m228ytXz9z38WL0tatzgF3zx4z9O7eLX38sdnOz89cdeHqC8yqVWN6AgDAvRBmAQ8TECA1bWpudsePX5mWYA+5V++zu+WWK9MS7CG3TJnC/wwAAOQWYRYoBkqXljp0MDfJvHvZ3r3Oo7dJSeYte5cvNze7ypWdR28bNDAvOgMAoCggzALFkM0mVa1qbn36mPsuXzZv4nD16O3PP0vJyeb22WdmOx8fqW5d59HbmjXNKQ8AABQ2wiwASeYc2kaNzG3YMHPfyZPmDR2uHsE9ckT64QdzmzbNbBcSkvXuZeHhln0UAEAxQpgFkKNSpaR77zU3yZyesH+/89q3W7ZIp09L33xjbnYREc6rJ8TESCVK5P69MzKkxETzxhHh4VKLFuZ6vAAAXI0wCyDXbDapUiVze/BBc196urRjh/Po7Y4d0oED5jZ/vtnOy0u6/Xbn0dvatc1pC9dasEAaMcI83i4iQnrnnSt3TQMAQCLMArhJPj7mmrX16kmPPmruO3PGHLG9OuAePGjeonf7dunDD812wcHmiO3V8283bTKDsmE4v8/Bg1L37tK8eQRaAMAVhFkALleypHT33eZmd/Cg8/JgmzZJZ89Ka9eam52XV9YgK5n7bDZp5EipWzemHAAATIRZAIWiYkXp/vvNTTLnxP7885Vwu2GDuZpCZmbO57DP2X3hBalrV/MmD2Fh3OgBAIozwiwAS3h7m3Nob79dGjjQ3BcXd+Xn63njDXOTpNBQM9RWr25u1apJlSvbdOqUX7YjvDeDi9IAoOghzAIoMqKjc9eufn3p2DHzArFTp8z5uVu2XN3CR1IHDR9uZAm69se8juhyURoAFE2EWQBFRosWZkA8eDD7ebM2m/n65s3miOiFC9KePdJvv0m7d1/9aGj/fptOnbJlE3RN2Y3o5hR0FywwLz7jojQAKHoIswCKDG9vc6Sze3czTF4dHu3hctKkK7/aDwyU6tQxt6ulpaVr4cKvVKPGX7Vvn68j5NoD7/79OY3omq4OulWrSlOmcFEaABRVhFkARUpsrDnSmd2v9CdNyv0IqL9/pm6/3ZyScK0LF6S9e68dzTUfbxR0r2W/KC0x0Xn1BgBA4SDMAihyYmPNkc6CutgqMPDKxWfXujbofvml853NcpKa6praAAB5Q5gFUCR5e1sz0nlt0G3UKHdhNjn5yrQDAEDh8bK6AAAoyuwXpd0opD7/vNSggTlF4npr5QIAXIswCwDXYb8oTcoaaG02c7vvPqlECenHH81b8dapI338sZSeXujlAkCxQ5gFgBuwX5RWsaLz/ogIc//ChdLvv0svvSSVKiXt2iU9/LBUs6Y0fbp0+bIlZQNAsUCYBYBciI2V9u2TVq2SPv3UfExOvrK6wq23SmPHmm1ef91cq3bPHmnIEHOZr8mTpYsXLfwAAOChCLMAkEv2i9J69zYfs1tdITRUGjPGDLVvvy2VL28u3fW3v0mVK0sTJ0rnzhVy4QDgwQizAFAAgoOl0aPN0dvJk6XISOnwYenJJ83b9o4fL50+bXWVAOD+CLMAUIACAqRhw8w1az/80Lyj2LFj0nPPSVFR5tSEEyesrhIA3BdhFgAKgZ+fNHiw9PPP5koHtWpJJ09K48aZofbZZ6WjR62uEgDcD2EWAAqRj4/Ut6/000/S559L9epJZ89Kb75pTj8YNUo6eNDqKgHAfRBmAcACXl5S9+5SUpK0eLF0553mrXQnTZKqVJEef9y8iAwAcH2EWQCwkM0mdekibdggLV8u/eUv5rq006ZJ1atLgwZJu3dbXSUAFF2EWQAoAmw2qV07KTFRWrNGatvWvIPYzJnmzRf69pV27LC6SgAoeiwPs1OmTFHlypUVEBCgmJgYJSYmXrf9J598onr16ikoKEjh4eEaOHCgjh8/XkjVAkDBa9lSWrFCWr9e6txZysw0b9RQp470wAPSDz9YXSEAFB2Whtk5c+Zo5MiRev7555WUlKQWLVqoQ4cOSklJybb9t99+q379+mnw4MHasWOHPv/8c23atElDhgwp5MoBoOA1bSotWWKG1wceMPctWCDFxJgh9/vvra0PAIoCHyvffOLEiRo8eLAjjE6aNEnLly/X1KlTNX78+Cztv//+e0VHR2v48OGSpMqVK+uxxx7ThAkTcnyPS5cu6dKlS47np/+3SnlaWprS0tJc8jns53HV+WAN+tFzeFpf1qkjzZ5tTjOYMMFbc+bYtGyZTcuWSW3aZOq55zLVooUhm83qSl3L0/qxuKIfPUNh92Ne3sdmGIZRgLXk6PLlywoKCtLnn3+u+++/37F/xIgR2rp1q9asWZPlmHXr1ql169ZauHChOnTooKNHj6pHjx6qVauWpk2blu37jB07VuPGjcuy/9NPP1VQUJDrPhAAFJJDh4I1f351rV4dqYwM8xdstWodV48ev6h+/T88LtQCKH7Onz+vPn366NSpUwoJCbluW8vC7KFDh1SxYkV99913at68uWP/66+/rv/+97/65Zdfsj1u3rx5GjhwoC5evKj09HR17dpV8+bNk6+vb7btsxuZjYyM1LFjx2745eRWWlqaEhIS1LZt2xzrQNFHP3qO4tKXv/8uvfWWl2bO9NLly2aCbdQoU2PGZKpzZ/cfqS0u/ejp6EfPUNj9ePr0aYWFheUqzFo6zUCSbNf819YwjCz77Hbu3Knhw4frxRdfVPv27ZWamqqnn35aQ4cO1fTp07M9xt/fX/7+/ln2+/r6urwzCuKcKHz0o+fw9L6sVs1cwuvFF6W33jJ/3rzZSw884KW6daUXXpBiYyVvb6srvTme3o/FBf3oGQqrH/PyHpZdABYWFiZvb28dPnzYaf/Ro0dVrly5bI8ZP3687rrrLj399NOqW7eu2rdvrylTpmjGjBlKTU0tjLIBoMipUEGaONG8ycKzz0olSkjbtkk9epjzbWfNMpf5AgBPZFmY9fPzU0xMjBISEpz2JyQkOE07uNr58+fl5eVcsvf/hhwsmi0BAEVG2bLS+PHm9IOxY6VSpaSff5b69ZNuu0368EPzhgwA4EksXZpr9OjR+vDDDzVjxgzt2rVLo0aNUkpKioYOHSpJGjNmjPr16+do36VLFy1YsEBTp07V3r179d1332n48OFq3LixKlSoYNXHAIAi5dZbpZdeMkPt+PFSWJi0d6/0yCPm1IT/+z/z1rkA4AksDbM9e/bUpEmT9PLLL6t+/fpau3at4uPjFRUVJUlKTU11WnN2wIABmjhxov7v//5PderU0YMPPqjbbrtNCxYssOojAECRFRJiTjvYt8+chhAeLu3fL/3971KVKtLbb0vnzlldJQDcHMvvADZs2DDt27dPly5d0pYtW9SyZUvHa3FxcVq9erVT+7///e/asWOHzp8/r0OHDunjjz9WxYoVC7lqAHAfwcHSqFHm6OzkyVKlStLhw9JTT0lRUdLrr0unTlldJQDkj+VhFgBQOAICpGHDpN27penTpapVpePHpeefN0Ptiy+azwHAnRBmAaCY8fOTBg0yLw77+GOpVi1zZPaVV6ToaOkf/5COHLG6SgDIHcIsABRTPj5S377STz9J8+ZJ9etLZ89KEyZIlStLI0dKBw9aXSUAXB9hFgCKOS8v6YEHpB9+kJYskRo3Nlc7eOcd80KxoUPNi8gAoCgizAIAJEk2m9S5s/T999KKFVLLlua6tO+/by7pNXCg9OuvVlcJAM4IswAAJzab1LattGaNubVtK2VkSHFx5vzaPn3MqQkAUBQQZgEAOWrZ0hyl/f57qUsXKTNTmj1buuMOKTZW2rIl6zEZGdLq1Wa71avN5wBQUAizAIAbatJEWrxYSkqSunc3R28XLpQaNZI6dZLWrzfbLVhgrojQurU5gtu6tfmce9sAKCiEWQBArtWvL33+uTnN4KGHzIvH4uOl5s3N0doHHpAOHHA+5uBBMwATaAEUBMIsACDPateWZs2SfvlFGjxY8vbOeR6tYZiPI0cy5QCA6xFmAQD5Vq2a9OGH5s0XrscwpP37pcTEwqkLQPFBmAUA3DT76OuNpKYWbB0Aih/CLADgpoWHu7YdAOQWYRYAcNNatJAiIsxVDnISEWG2AwBXIswCAG6at7d5+1sp50AbGWmuUwsArkSYBQC4RGysNG+eVLGi8/6wMDPsrl8v9e0rpaVZUx8Az0SYBQC4TGystG+ftGqV9Omn5uPhw9KiRZKvr7lGLYEWgCv5WF0AAMCzeHtLd9/tvK9zZ/OmCQ88YAZawzDDrq+vJSUC8CCMzAIACkXnztL8+ZKfnzkdoU8fRmgB3DzCLACg0BBoAbgaYRYAUKgItABciTALACh0BFoArkKYBQBYgkALwBUIswAAyxBoAdwswiwAwFL2ZbsItADygzALALBcp07OgbZ3bwItgNwhzAIAioSrA+38+dJDD3krPd1mdVkAijjCLACgyLg60C5c6KW3327ECC2A6yLMAgCKlCuB1tD69RX00EPeBFoAOSLMAgCKnE6dpLlzM+Tjk6GFC72YQwsgR4RZAECR1LGjoWef3Sg/P0Pz53NRGIDsEWYBAEVWo0ZH9fnnGY6Lwgi0AK5FmAUAFGkdOhhauFAEWgDZIswCAIq8jh3lFGh79SLQAjARZgEAbuHqQLtgAYEWgIkwCwBwGwRaANcizAIA3AqBFsDVCLMAALfTsaO0aBGBFgBhFgDgpjp0INACIMwCANwYgRYAYRYA4NauDbQ9exJogeKEMAsAcHtXB9qFCwm0QHFCmAUAeAR7oPX3J9ACxQlhFgDgMXIKtBkZ0urV0uzZ5mNGhsWFAnAZH6sLAADAlf76VzPQ3nefGWj/8hfp4EFzs4uIkN55R4qNtapKAK7CyCwAwOPYA62Pj7Rxo3OQlczn3bubF4wBcG+EWQCAR2rbVipVKvvXDMN8HDmSKQeAuyPMAgA8UmKidOxYzq8bhrR/v9kOgPsizAIAPFJqqmvbASiaCLMAAI8UHu7adgCKJsIsAMAjtWhhrlpgs12/3dy50unThVMTANcjzAIAPJK3t7n8lpQ10F79fOpUqVYtcxkvAO6HMAsA8FixsdK8eVLFis77IyKk+fOllSulatWkQ4fMtvfdZ14UBsB9EGYBAB4tNlbat09atUr69FPzMTnZ3N+mjbRtm/T88+aatF98IdWuLb37Lkt2Ae6CMAsA8Hje3tLdd0u9e5uP3t5XXgsMlF59Vdq6VWreXDp7VhoxQmrWzNwHoGgjzAIAIOn22801Z6dNk0JDpU2bpEaNpKefls6ds7o6ADkhzAIA8D9eXtJjj0m7dkk9ephTDd56S6pTR/ryS6urA5AdwiwAANcID5fmzJGWLpUqVTLn3HbsaE5TOHLE6uoAXI0wCwBADjp1knbskEaPNkdtP/tMqllT+uADKTPT6uoASIRZAACuq0QJ6e23zTm0MTHSyZPSo49KrVqZ0xEAWIswCwBALjRsKH3/vTRxohQcLH37rVSvnvTii9LFi1ZXBxRfhFkAAHLJx0caNUrauVPq3FlKS5NeecUMtatXW10dUDwRZgEAyKNKlaTFi6XPPzcvFvv1V6l1a2nQIOn4caurA4oXwiwAAPlgs0ndu5vzZh9/3Hw+c6Z5gdjHH0uGYXWFQPFAmAUA4CaEhkpTpkjffWeuR3vsmPTww1L79tKePVZXB3g+wiwAAC7QrJm0ZYv0+uuSv7+UkGCG2zfeMOfWAigYhFkAAFzEz08aM0b66SfpnnvMVQ7GjDGX9Pr+e6urAzwTYRYAABerVs0cmf3oIyksTNq+XWreXHriCenUKaurAzwLYRYAgAJgs5lzZ3ftkgYMMC8ImzJFqlVLmj+fC8QAVyHMAgBQgMLCzFUOVq6UqleXUlPNVRC6dZP277e6OsD9EWYBACgEbdpI27ZJL7wg+fpKS5aYo7STJkkZGVZXB7gvwiwAAIUkIMC8Y9jWrdJdd0nnzpl3FGvaVEpKsro6wD0RZgEAKGS1a0tr10rTppnr1G7eLN15p/TUU2bABZB7hFkAACzg5SU99ph5gViPHuZUg7fflm6/XYqPt7o6wH0QZgEAsFB4uDRnjrRsmRQVJf3+u9Spk9Szp3T48JV2GRnS6tXS7NnmI/NsARNhFgCAIqBjR2nHDunJJ81R27lzpZo1pf/8R5o3T4qOllq3lvr0MR+jo6UFC6yuGrAeYRYAgCIiOFh66y1zDm1MjHmDhccekx58UDpwwLntwYPmEl8EWhR3lofZKVOmqHLlygoICFBMTIwSExOv2/7SpUt6/vnnFRUVJX9/f1WtWlUzZswopGoBACh4DRpIGzZIEyeaN1/Ijv2mCyNHMuUAxZuPlW8+Z84cjRw5UlOmTNFdd92l999/Xx06dNDOnTtVqVKlbI/p0aOHjhw5ounTp6tatWo6evSo0tPTC7lyAAAKlre3GWqvd6cwwzBvvJCYKN19d6GVBhQplobZiRMnavDgwRoyZIgkadKkSVq+fLmmTp2q8ePHZ2n/1Vdfac2aNdq7d69uvfVWSVJ0dHRhlgwAQKFJTXVtO8ATWRZmL1++rC1btujZZ5912t+uXTutW7cu22MWL16sRo0aacKECZo1a5aCg4PVtWtXvfLKKwoMDMz2mEuXLunSpUuO56dPn5YkpaWlKS0tzSWfxX4eV50P1qAfPQd96RnoR6lMGZty87/qlSsz1L59pkqWLPia8op+9AyF3Y95eR/LwuyxY8eUkZGhcuXKOe0vV66cDl+9FslV9u7dq2+//VYBAQFauHChjh07pmHDhunEiRM5zpsdP368xo0bl2X/ihUrFBQUdPMf5CoJCQkuPR+sQT96DvrSMxTnfszIkEqXbqfjxwMkZTd51pBk0/Tp3po7N0OdO+9Rp057VaJE0Zt+V5z70ZMUVj+eP38+121thnG92TgF59ChQ6pYsaLWrVunZs2aOfa/9tprmjVrln7++ecsx7Rr106JiYk6fPiwQkNDJUkLFixQ9+7dde7cuWxHZ7MbmY2MjNSxY8cUEhLiks+SlpamhIQEtW3bVr6+vi45Jwof/eg56EvPQD+aFi60qVcvb0mSYVwJtDab+b/voUMz9fXXXtq923wtJMTQsGGZGj48U2FhhV/vtehHz1DY/Xj69GmFhYXp1KlTN8xrlo3MhoWFydvbO8so7NGjR7OM1tqFh4erYsWKjiArSbVq1ZJhGDpw4ICqV6+e5Rh/f3/5+/tn2e/r6+vyziiIc6Lw0Y+eg770DMW9H3v0kHx8pBEjnJfnioiwadIkKTbWWxkZ0uefS6++Ku3YYdMbb3jrvfe89fjj5rq15ctbVr5Dce9HT1FY/ZiX97BsaS4/Pz/FxMRkGa5OSEhQ8+bNsz3mrrvu0qFDh3T27FnHvl9//VVeXl6KiIgo0HoBALBKbKy0b5+0apX06afmY3KyuV8yVz7o1Uvats1cd7ZBA+ncOXPN2sqVpeHDs65TC3gKS9eZHT16tD788EPNmDFDu3bt0qhRo5SSkqKhQ4dKksaMGaN+/fo52vfp00elS5fWwIEDtXPnTq1du1ZPP/20Bg0alOMFYAAAeAJvb3P5rd69zUdv76xtvLyk+++Xtmwxb4/btKl08aL03ntSlSrmDRiSkwu7cqBgWRpme/bsqUmTJunll19W/fr1tXbtWsXHxysqKkqSlJqaqpSUFEf7EiVKKCEhQSdPnlSjRo3Ut29fdenSRe+++65VHwEAgCLHZjNvj7tunfT111KrVlJamnlr3OrVpYEDpV9/tbpKwDUsXWdWkoYNG6Zhw4Zl+1pcXFyWfTVr1uSKSAAAcsFmk+65x9wSE805tStWSHFx0kcfST17Ss89J9WpY3WlQP5ZfjtbAABQ8Fq0kJYvl77/XurSRcrMlGbPlu64Q3rgASkpyeoKgfwhzAIAUIw0aSItXmyG1wceMPctWCA1bCh17ixt2GBtfUBeEWYBACiG6teX5s2TfvpJ6tPHvHjMftFY27bS2rVWVwjkDmEWAIBi7PbbpU8+kX7+2bwwzMfnykVjLVtKCQmSNbdXAnKHMAsAAFS9ujRjhrR7t7mEl5+fedFYu3ZSs2bS0qWEWhRNhFkAAOAQHS1Nmybt2WPebCEgwJxH26WLOa92/nzz4jGgqCDMAgCALCIipHfeMe889vTTUnCwtHWr1L27VLeuuRJCRobVVQKEWQAAcB3lykkTJpih9oUXpJAQaccO86KxWrXMNWvT0qyuEsUZYRYAANxQWJj0yivS77+bj7feas6vHThQqlFDev996dIlq6tEcUSYBQAAuVaqlDlCu2+f9OabUtmy5s9Dh0pVq0rvvitduGBxkShWCLMAACDPSpaUnnlGSk6WJk2SKlSQDh6URoyQKleW/vUv6exZq6tEcUCYBQAA+RYUZAbYvXulqVOlqCjpyBEz6EZHS+PHe+ncOR+ry4QHI8wCAICb5u9vTjXYvdtcr7ZaNen4cemll7z1yCPtNHasl44ft7pKeCLCLAAAcBlfX/OisF27zDuL1apl6Px5X73+ureio6V//EM6etTqKuFJCLMAAMDlfHzM5buSktL1zDMbVbeuobNnzWW+oqOlkSPNObbAzSLMAgCAAuPlJTVvnqpNm9K1eLF0553magfvvCNVqSI9/ri53BeQX4RZAABQ4Gw285a4GzZIy5dLf/mLdPmyeevcatWkQYOk336zukq4I8IsAAAoNDab1K6dlJgorV4t3XOPlJ4uzZwp3Xab9NBD0s6dVlcJd0KYBQAAlmjVSvr6a2ndOqljRykz07xorE4d6cEHpa1bsx6TkWGG4NmzzceMjEIuGkUOYRYAAFiqWTNp2TJpyxbp/vslw5DmzZMaNJC6dpU2bjTbLVhgXjzWurV5cVnr1ubzBQusrB5WI8wCAIAioWFDM5hu2yb16mVOSViyRGrSRKpfX3rgAenAAedjDh6Uuncn0BZnhFkAAFCk3HGHOY1g1y6pf39zRYQff8y+rWGYjyNHMuWguCLMAgCAIum226S4OGnWrOu3Mwxp/37zojIUP4RZAABQpNlsuWuXmlqwdaBoIswCAIAiLTzcte3gWQizAACgSGvRQoqIyHmE1maTIiPNdih+CLMAAKBI8/Y2b38r5RxoJ00y26H4IcwCAIAiLzbWXHu2YkXn/d7e0ty55usongizAADALcTGSvv2SatWmascBAeby3GFhlpdGaxEmAUAAG7D21u6+25z/dn+/c19M2ZYWhIsRpgFAABuadAg83HhQunPP62tBdbxyW3DxYsX5/qkXbt2zVcxAAAAudWwoXm3sO3bzTuGDRtmdUWwQq7D7H333ZerdjabTRncTw4AABQwm80cnR01Spo5kzBbXOV6mkFmZmauNoIsAAAoLH37Sr6+0ubN0rZtVlcDKzBnFgAAuK0yZaQuXcyfZ860thZYI9fTDN59991cn3T48OH5KgYAACCvBg2SFiyQPv5YevNNyc/P6opQmHIdZv/973/nqp3NZiPMAgCAQtO+vRQeLqWmSkuXcgOF4ibXYTY5Obkg6wAAAMgXHx+pXz9zVHbmTMJsccOcWQAA4PYGDjQf4+OlQ4esrQWFK9cjs9c6cOCAFi9erJSUFF2+fNnptYkTJ950YQAAALl1221S8+bSunXSrFnSP/5hdUUoLPkKsytXrlTXrl1VuXJl/fLLL6pTp4727dsnwzDUsGFDV9cIAABwQ4MGmWF25kzpmWfMdWjh+fI1zWDMmDF68skn9dNPPykgIEDz58/X/v371apVKz344IOurhEAAOCGevSQgoKkX36R1q+3uhoUlnyF2V27dql///6SJB8fH124cEElSpTQyy+/rDfffNOlBQIAAORGyZKSfUyNNWeLj3yF2eDgYF26dEmSVKFCBe3Zs8fx2rFjx1xTGQAAQB4NGmQ+fvaZdO6ctbWgcOQrzDZt2lTfffedJKlTp0568skn9dprr2nQoEFq2rSpSwsEAADIrRYtpKpVpbNnpXnzrK4GhSFfYXbixIlq0qSJJGns2LFq27at5syZo6ioKE2fPt2lBQIAAOSWzXZlmS6mGhQP+VrNoEqVKo6fg4KCNGXKFJcVBAAAcDP695f++U9pzRppzx5zpBaeK18js5s2bdKGDRuy7N+wYYM2b95800UBAADkV0SE1K6d+XNcnKWloBDkK8w+8cQT2r9/f5b9Bw8e1BNPPHHTRQEAANwM+4VgcXFSRoalpaCA5SvM7ty5M9ubIzRo0EA7d+686aIAAABuRrdu0q23SgcOSCtXWl0NClK+wqy/v7+OHDmSZX9qaqp8fPJ9h1wAAACX8PeX+vQxf54xw9paULDyFWbbtm2rMWPG6NSpU459J0+e1HPPPae2bdu6rDgAAID8sk81WLhQOnHC2lpQcPIVZt9++23t379fUVFRat26tVq3bq3KlSvr8OHDevvtt11dIwAAQJ41aCDVqyddvizNnm11NSgo+ZoTULFiRW3btk2ffPKJfvzxRwUGBmrgwIHq3bu3fH19XV0jAABAvgwaJI0YIb3zjjmHNjzcvLGCt7fVlcFV8j3BNTg4WI8++qgrawEAAHCp0FDzcffuK3NoIyLMcBsba11dcJ18TTOQpFmzZukvf/mLKlSooN9//12S9O9//1tffPGFy4oDAADIrwULrtwN7GoHD0rdu5uvw/3lK8xOnTpVo0ePVocOHfTnn38q438LuN1yyy2aNGmSK+sDAADIs4wMc3qBYWR9zb5v5EjWoPUE+Qqz7733nj744AM9//zzTktxNWrUSNu3b3dZcQAAAPmRmGiuMZsTw5D27zfbwb3lK8wmJyerQYMGWfb7+/vr3LlzN10UAADAzUhNdW07FF35CrOVK1fW1q1bs+z/8ssvVatWrZutCQAA4KaEh7u2HYqufK1m8PTTT+uJJ57QxYsXZRiGNm7cqNmzZ+v111/X9OnTXV0jAABAnrRoYa5acPBg9vNm7RISpJYtJa98XxIPq+UrzA4cOFDp6el65plndP78efXp00cVK1bUe++9pxYtWri6RgAAgDzx9jaX3+reXbLZnAPt1c9ff13aulX65BOpVCkrKsXNyve/Qx555BH9/vvvOnr0qA4fPqyNGzcqKSlJ1apVc2V9AAAA+RIbK82bJ1Ws6Lw/IkKaP1/6+GMpIECKj5fuvFP66Sdr6sTNyVOYPXnypPr27asyZcqoQoUKevfdd3Xrrbdq8uTJqlatmr7//nvNmDGjoGoFAADIk9hYad8+adUq6dNPzcfkZHN/377SunVSVJT0229S06Zm+IV7ydM0g+eee05r165V//799dVXX2nUqFH66quvdPHiRcXHx6tVq1YFVScAAEC+eHtLd9+d/WsNGkibN0u9ekkrV0oPPij94x/Sa69xy1t3kaeR2WXLlmnmzJl66623tHjxYhmGoRo1auibb74hyAIAALcUFiZ99ZX09NPm8zfflDp2lE6csLYu5E6ewuyhQ4dUu3ZtSVKVKlUUEBCgIUOGFEhhAAAAhcXHR5owQfrsMykoSFqxQmrUSPrxR6srw43kKcxmZmbK19fX8dzb21vBwcEuLwoAAMAKPXtK69dLVaqYc2ubNZNmz7a6KlxPnubMGoahAQMGyN/fX5J08eJFDR06NEugXbBggesqBAAAKER160qbNkl9+kjLl5uPmzeb0w988rWoKQpSnrqkf//+Ts8feughlxYDAABQFNx6q7RsmfTii+ZatBMnmuvRfvaZVKaM1dXhankKszNnziyoOgAAAIoUb29zVYOYGKl/f+mbb8x5tAsXSg0bWl0d7Lh5GwAAwHXExkobNkjVq0spKdJdd0kffWR1VbAjzAIAANxA7drSxo1S587SxYvmSO3w4VJamtWVgTALAACQC6VKSV98Ib30kvn8vfeke++VjhyxtKxijzALAACQS15e0tixZqgtWVJau9acU7txo9WVFV+EWQAAgDzq2tVcvqtmTengQalFC2n6dKurKp4IswAAAPlw223mhWH33SddviwNGSI9/rj5MwqP5WF2ypQpqly5sgICAhQTE6PExMRcHffdd9/Jx8dH9evXL9gCAQAAchASIs2fL736qmSzSdOmSa1bS6mpVldWfFgaZufMmaORI0fq+eefV1JSklq0aKEOHTooJSXlusedOnVK/fr10z333FNIlQIAAGTPy0t6/nlp6VIpNFRat86cR7tundWVFQ+WhtmJEydq8ODBGjJkiGrVqqVJkyYpMjJSU6dOve5xjz32mPr06aNmzZoVUqUAAADX17Gjedvb2283R2bvvlt6/33JMKyuzLNZdofhy5cva8uWLXr22Wed9rdr107rrvNPmZkzZ2rPnj36+OOP9eqrr97wfS5duqRLly45np8+fVqSlJaWpjQXLQ5nP4+rzgdr0I+eg770DPSjZyhu/RgVJSUmSkOGeGvBAi8NHSpt2JCpd97JUECA1dXlX2H3Y17ex7Iwe+zYMWVkZKhcuXJO+8uVK6fDhw9ne8zu3bv17LPPKjExUT4+uSt9/PjxGjduXJb9K1asUFBQUN4Lv46EhASXng/WoB89B33pGehHz1Dc+vHhh6USJarp449ra+ZML3377Sn94x8bFRZ20erSbkph9eP58+dz3dayMGtns9mcnhuGkWWfJGVkZKhPnz4aN26catSokevzjxkzRqNHj3Y8P336tCIjI9WuXTuFhITkv/CrpKWlKSEhQW3btpWvr69LzonCRz96DvrSM9CPnqE492OnTlLPnhl66CFv7d59i557rp1mz85QixbuN++gsPvR/pv03LAszIaFhcnb2zvLKOzRo0ezjNZK0pkzZ7R582YlJSXpb3/7myQpMzNThmHIx8dHK1asUJs2bbIc5+/vL39//yz7fX19Xd4ZBXFOFD760XPQl56BfvQMxbUf7fNoY2OlH3+0qX17H/3739ITT5irH7ibwurHvLyHZReA+fn5KSYmJstwdUJCgpo3b56lfUhIiLZv366tW7c6tqFDh+q2227T1q1b1aRJk8IqHQAAINeqVDFXNujdW0pPl/7+d2nAAOnCBasr8wyWTjMYPXq0Hn74YTVq1EjNmjXTf/7zH6WkpGjo0KGSzCkCBw8e1EcffSQvLy/VqVPH6fiyZcsqICAgy34AAICiJChI+uQT6c47paeflj76SPrpJ2nBAvOiMeSfpWG2Z8+eOn78uF5++WWlpqaqTp06io+PV9T/ejU1NfWGa84CAAC4A5tNGjVKqldP6tlT+uEHqVEjae5c80YLyB/L7wA2bNgw7du3T5cuXdKWLVvUsmVLx2txcXFavXp1jseOHTtWW7duLfgiAQAAXKRNG3MebcOG0rFjUtu20sSJrEebX5aHWQAAgOImKkr69lupXz8pI0N68kmpb18pDytS4X8IswAAABYIDJTi4qR335V8fKTZs6XmzaXkZKsrcy+EWQAAAIvYbObqBitXSmXLSj/+aM6jXbHC6srcB2EWAADAYi1bSlu2SI0bSydOSB06SG++yTza3CDMAgAAFAEREdKaNdLgwVJmpvTss+aqB2fPWl1Z0UaYBQAAKCICAqQPPpCmTZN8faXPP5eaNpV++83qyoouwiwAAEARYrNJjz0mrV4tlS8v7dhh3mwhPt7qyoomwiwAAEAR1Ly5OY+2WTPp5Empc2fptdfMKQi4gjALAABQRFWoYI7QDh1qXgz2wgvSAw9Ip09bXVnRQZgFAAAowvz8pKlTpQ8/NH9etEhq0kT65RerKysaCLMAAABuYPBgae1aqWJF6eefzXm0ixdbXZX1CLMAAABuokkTcx5tixbSmTNSt27SSy9dmUebkWFOS5g923zMyLCy2sJBmAUAAHAj5cqZdwz7+9/N5y+/bIbaWbOk6GipdWupTx/zMTpaWrDAymoLHmEWAADAzfj6Su++K8XFSf7+0tKlUr9+0oEDzu0OHpS6d/fsQEuYBQAAcFP9+5vzaL29s3/dfjvckSM9d8oBYRYAAMCNnT9//aBqGNL+/VJiYuHVVJgIswAAAG4sNdW17dwNYRYAAMCNhYe7tp27IcwCAAC4sRYtpIgIyWbL/nWbTYqMNNt5IsIsAACAG/P2lt55x/z52kBrfz5pUs4Xibk7wiwAAICbi42V5s0z7w52tXLlzP2xsdbUVRgIswAAAB4gNlbat09atUpq0MDcN2SIZwdZiTALAADgMby9pbvvlp580nw+Z86VtWY9FWEWAADAw3TrJgUGSrt3S0lJVldTsAizAAAAHqZECalzZ/Pnzz6ztpaCRpgFAADwQL16mY9z5kiZmdbWUpAIswAAAB6oQwepZEkpJUVav97qagoOYRYAAMADBQZK999v/uzJUw0IswAAAB7KPtVg7lwpPd3aWgoKYRYAAMBD3XuvdOut0tGj0urVVldTMAizAAAAHsrXV+re3fzZU6caEGYBAAA8WO/e5uP8+dLly9bWUhAIswAAAB6sRQspPFw6eVJascLqalyPMAsAAODBvL2lHj3Mn2fPtraWgkCYBQAA8HD2qQZffCGdP29tLa5GmAUAAPBwjRtL0dHSuXPSsmVWV+NahFkAAAAPZ7NdWXPW01Y1IMwCAAAUA/Ywu2yZdOqUtbW4EmEWAACgGKhbV6pVS7p0yZw76ykIswAAAMWAp041IMwCAAAUE/Ywm5AgHTtmbS2uQpgFAAAoJmrUkBo2lNLTzTuCeQLCLAAAQDHiaVMNCLMAAADFiP1uYGvWSIcOWVuLKxBmAQAAipGoKKl5c8kwpNdfN29xu3q1lJFhdWX5Q5gFAAAoZmrVMh8nT5b69JFatzbvELZggaVl5QthFgAAoBhZsECaMSPr/oMHpe7d3S/QEmYBAACKiYwMacQIc4rBtez7Ro50rykHhFkAAIBiIjFROnAg59cNQ9q/32znLgizAAAAxURqqmvbFQWEWQAAgGIiPNy17YoCwiwAAEAx0aKFFBEh2WzZv26zSZGRZjt3QZgFAAAoJry9pXfeMX++NtDan0+aZLZzF4RZAACAYiQ2Vpo3T6pY0Xl/RIS5PzbWmrryizALAABQzMTGSvv2mTdLkKRhw6TkZPcLshJhFgAAoFjy9pbuuMP8OSTEvaYWXI0wCwAAUEyVLWs+Hj1qbR03gzALAABQTBFmAQAA4LbsYfaPP6yt42YQZgEAAIopRmYBAADgtsqUMR8JswAAAHA79pHZc+fMzR0RZgEAAIqpkiUlf3/zZ3edN0uYBQAAKKZsNvefN0uYBQAAKMbcfUUDwiwAAEAxxsgsAAAA3Ja7r2hAmAUAACjGGJkFAACA2yLMAgAAwG0RZgEAAOC2WM0AAAAAbouRWQAAALitq1czMAxra8kPwiwAAEAxZg+zaWnSqVPW1pIfhFkAAIBiLDBQKlnS/NkdpxoQZgEAAIo5d74IjDALAABQzLnzRWCEWQAAgGKOMHsTpkyZosqVKysgIEAxMTFKTEzMse2CBQvUtm1blSlTRiEhIWrWrJmWL19eiNUCAAB4nqtXNHA3lobZOXPmaOTIkXr++eeVlJSkFi1aqEOHDkpJScm2/dq1a9W2bVvFx8dry5Ytat26tbp06aKkpKRCrhwAAMBzuPPIrI+Vbz5x4kQNHjxYQ4YMkSRNmjRJy5cv19SpUzV+/Pgs7SdNmuT0/PXXX9cXX3yhJUuWqEGDBtm+x6VLl3Tp0iXH89OnT0uS0tLSlJaW5pLPYT+Pq84Ha9CPnoO+9Az0o2egH91D6dJekrx1+HCm0tIysrxe2P2Yl/exLMxevnxZW7Zs0bPPPuu0v127dlq3bl2uzpGZmakzZ87o1ltvzbHN+PHjNW7cuCz7V6xYoaCgoLwVfQMJCQkuPR+sQT96DvrSM9CPnoF+LNoOHqwoqZF++eW44uNzzmGF1Y/nz5/PdVvLwuyxY8eUkZGhcuXKOe0vV66cDh8+nKtzvP322zp37px69OiRY5sxY8Zo9OjRjuenT59WZGSk2rVrp5CQkPwVf420tDQlJCSobdu28vX1dck5UfjoR89BX3oG+tEz0I/uISDApokTpYyMMHXs2DHL64Xdj/bfpOeGpdMMJMlmszk9Nwwjy77szJ49W2PHjtUXX3yhsvaJHtnw9/eXv79/lv2+vr4u74yCOCcKH/3oOehLz0A/egb6sWgLDzcf//jDdt1+Kqx+zMt7WHYBWFhYmLy9vbOMwh49ejTLaO215syZo8GDB2vu3Lm69957C7JMAAAAj2cfFzx2TMrIOmW2SLMszPr5+SkmJibL3IuEhAQ1b948x+Nmz56tAQMG6NNPP1WnTp0KukwAAACPFxZmPhqGdPy4tbXklaXTDEaPHq2HH35YjRo1UrNmzfSf//xHKSkpGjp0qCRzvuvBgwf10UcfSTKDbL9+/fTOO++oadOmjlHdwMBAhYaGWvY5AAAA3JmPj1S6tBlkjx69MlLrDiwNsz179tTx48f18ssvKzU1VXXq1FF8fLyioqIkSampqU5rzr7//vtKT0/XE088oSeeeMKxv3///oqLiyvs8gEAADxG2bJmmP3jD6sryRvLLwAbNmyYhg0blu1r1wbU1atXF3xBAAAAxVDZstKuXe534wTLb2cLAAAA67nrLW0JswAAAHDbW9oSZgEAAECYBQAAgPsizAIAAMBt2cOsu61mQJgFAAAAI7MAAABwX6xmAAAAALdlH5k9dUq6dMnaWvKCMAsAAACVKmXe1lZyr3mzhFkAAADIy+vKVAPCLAAAANyOO14ERpgFAACAJMIsAAAA3Jg7rmhAmAUAAIAkRmYBAADgxgizAAAAcFvueEtbwiwAAAAkMTILAAAAN0aYBQAAgNu6ejUDw7C2ltwizAIAAEDSlZHZCxekc+esrSW3CLMAAACQJAUHS4GB5s/uMtWAMAsAAABJks3mfisaEGYBAADg4G4XgRFmAQAA4ECYBQAAgNu6ekUDd0CYBQAAgAMjswAAAHBbXAAGAAAAt8XILAAAANwWYRYAAABuizALAAAAt2VfzeCPP6TMTGtryQ3CLAAAABzsYTY9XTp50tJScoUwCwAAAAd/fyk01PzZHVY0IMwCAADAiTvNmyXMAgAAwAlhFgAAAG6LMAsAAAC3Zb8IjDALAAAAt8PILAAAANyWPcyymgEAAADcDiOzAAAAcFuEWQAAALgtwiwAAADcln01g+PHzdvaFmWEWQAAADgpXVqy2cyfjx+3tpYbIcwCAADAibe3FBZm/lzUpxoQZgEAAJCFu8ybJcwCAAAgC8IsAAAA3BZhFgAAAG7LvqIBYRYAAABux11uaUuYBQAAQBZMMwAAAIDbIswCAADAbRFmAQAA4LYIswAAAHBb9tUMzpyRLl60tpbrIcwCAAAgi9BQydfX/Lkor2hAmAUAAEAWNpt7LM9FmAUAAEC2rsybtVlbyHUQZgEAAJAtd7gIjDALAACAbF2ZZsDILAAAANyMfUUD5swCAADA7TAyCwAAALfFagYAAABwW1wABgAAALfFNAMAAAC4ratHZg3D2lpyQpgFAABAtuyrGVy6ZNPFiz7WFpMDwiwAAACyFRQkBQebP5886WdtMTkgzAIAACBH9qkGp075W1tIDgizAAAAyBFhFgAAAG6LMAsAAAC3RZgFAACA27KvaHDqFBeAAQAAwM0wMgsAAAC3RZgFAACA27oSZplmAAAAADdTurT5+McfgVqzxqaMDGvruZblYXbKlCmqXLmyAgICFBMTo8TExOu2X7NmjWJiYhQQEKAqVapo2rRphVQpAABA8bJggdS5s/nz+fN+atvWR9HR5v6iwtIwO2fOHI0cOVLPP/+8kpKS1KJFC3Xo0EEpKSnZtk9OTlbHjh3VokULJSUl6bnnntPw4cM1f/78Qq4cAADAsy1YIHXvLqWmOu8/eNDcX1QCraVhduLEiRo8eLCGDBmiWrVqadKkSYqMjNTUqVOzbT9t2jRVqlRJkyZNUq1atTRkyBANGjRIb731ViFXDgAA4LkyMqQRIyTDyPqafd/IkSoSUw58rHrjy5cva8uWLXr22Wed9rdr107r1q3L9pj169erXbt2Tvvat2+v6dOnKy0tTb6+vlmOuXTpki5duuR4fvr0aUlSWlqa0tLSbvZjOM519SPcE/3oOehLz0A/egb60T2tWWPTgQM5x0TDkPbvl1atSlerVtkk3puUlz8vloXZY8eOKSMjQ+XKlXPaX65cOR0+fDjbYw4fPpxt+/T0dB07dkzh4eFZjhk/frzGjRuXZf+KFSsUFBR0E58gq4SEBJeeD9agHz0HfekZ6EfPQD+6l7VrK0pqdMN2X365VefOHXT5+58/fz7XbS0Ls3Y2m83puWEYWfbdqH12++3GjBmj0aNHO56fPn1akZGRateunUJCQvJbtpO0tDQlJCSobdu22Y4Owz3Qj56DvvQM9KNnoB/dU3CwTRMn3rhdhw711apVPZe/v/036blhWZgNCwuTt7d3llHYo0ePZhl9tStfvny27X18fFTavm7ENfz9/eXvn3WRX19fX5f/pSqIc6Lw0Y+eg770DPSjZ6Af3Uvr1lJEhHmxV3bzZm028/XWrX3k7e3698/LnxXLLgDz8/NTTExMll87JCQkqHnz5tke06xZsyztV6xYoUaNGvEXBAAAwEW8vaV33jF/vvaX3/bnkyapQIJsXlm6msHo0aP14YcfasaMGdq1a5dGjRqllJQUDR06VJI5RaBfv36O9kOHDtXvv/+u0aNHa9euXZoxY4amT5+up556yqqPAAAA4JFiY6V586SKFZ33R0SY+2NjranrWpbOme3Zs6eOHz+ul19+WampqapTp47i4+MVFRUlSUpNTXVac7Zy5cqKj4/XqFGjNHnyZFWoUEHvvvuuHnjgAas+AgAAgMeKjZW6dTNXLfjyy63q0KF+gU0tyC/LLwAbNmyYhg0blu1rcXFxWfa1atVKP/zwQwFXBQAAAMmcStCqlaFz5w6qVat6RSrISkXgdrYAAABAfhFmAQAA4LYIswAAAHBbhFkAAAC4LcIsAAAA3BZhFgAAAG6LMAsAAAC3RZgFAACA2yLMAgAAwG0RZgEAAOC2CLMAAABwW4RZAAAAuC3CLAAAANyWj9UFFDbDMCRJp0+fdtk509LSdP78eZ0+fVq+vr4uOy8KF/3oOehLz0A/egb60TMUdj/ac5o9t11PsQuzZ86ckSRFRkZaXAkAAACu58yZMwoNDb1uG5uRm8jrQTIzM3Xo0CGVLFlSNpvNJec8ffq0IiMjtX//foWEhLjknCh89KPnoC89A/3oGehHz1DY/WgYhs6cOaMKFSrIy+v6s2KL3cisl5eXIiIiCuTcISEh/EX1APSj56AvPQP96BnoR89QmP14oxFZOy4AAwAAgNsizAIAAMBtEWZdwN/fXy+99JL8/f2tLgU3gX70HPSlZ6AfPQP96BmKcj8WuwvAAAAA4DkYmQUAAIDbIswCAADAbRFmAQAA4LYIswAAAHBbhNlcmjJliipXrqyAgADFxMQoMTHxuu3XrFmjmJgYBQQEqEqVKpo2bVohVYrryUs/LliwQG3btlWZMmUUEhKiZs2aafny5YVYLXKS17+Pdt999518fHxUv379gi0QuZbXvrx06ZKef/55RUVFyd/fX1WrVtWMGTMKqVrkJK/9+Mknn6hevXoKCgpSeHi4Bg4cqOPHjxdStcjO2rVr1aVLF1WoUEE2m02LFi264TFFJusYuKHPPvvM8PX1NT744ANj586dxogRI4zg4GDj999/z7b93r17jaCgIGPEiBHGzp07jQ8++MDw9fU15s2bV8iV42p57ccRI0YYb775prFx40bj119/NcaMGWP4+voaP/zwQyFXjqvltR/tTp48aVSpUsVo166dUa9evcIpFteVn77s2rWr0aRJEyMhIcFITk42NmzYYHz33XeFWDWuldd+TExMNLy8vIx33nnH2Lt3r5GYmGjcfvvtxn333VfIleNq8fHxxvPPP2/Mnz/fkGQsXLjwuu2LUtYhzOZC48aNjaFDhzrtq1mzpvHss89m2/6ZZ54xatas6bTvscceM5o2bVpgNeLG8tqP2aldu7Yxbtw4V5eGPMhvP/bs2dN44YUXjJdeeokwW0TktS+//PJLIzQ01Dh+/HhhlIdcyms//utf/zKqVKnitO/dd981IiIiCqxG5E1uwmxRyjpMM7iBy5cva8uWLWrXrp3T/nbt2mndunXZHrN+/fos7du3b6/NmzcrLS2twGpFzvLTj9fKzMzUmTNndOuttxZEiciF/PbjzJkztWfPHr300ksFXSJyKT99uXjxYjVq1EgTJkxQxYoVVaNGDT311FO6cOFCYZSMbOSnH5s3b64DBw4oPj5ehmHoyJEjmjdvnjp16lQYJcNFilLW8SnUd3NDx44dU0ZGhsqVK+e0v1y5cjp8+HC2xxw+fDjb9unp6Tp27JjCw8MLrF5kLz/9eK23335b586dU48ePQqiRORCfvpx9+7devbZZ5WYmCgfH/6TV1Tkpy/37t2rb7/9VgEBAVq4cKGOHTumYcOG6cSJE8ybtUh++rF58+b65JNP1LNnT128eFHp6enq2rWr3nvvvcIoGS5SlLIOI7O5ZLPZnJ4bhpFl343aZ7cfhSuv/Wg3e/ZsjR07VnPmzFHZsmULqjzkUm77MSMjQ3369NG4ceNUo0aNwioPeZCXv5OZmZmy2Wz65JNP1LhxY3Xs2FETJ05UXFwco7MWy0s/7ty5U8OHD9eLL76oLVu26KuvvlJycrKGDh1aGKXChYpK1mGY4gbCwsLk7e2d5V+YR48ezfIvErvy5ctn297Hx0elS5cusFqRs/z0o92cOXM0ePBgff7557r33nsLskzcQF778cyZM9q8ebOSkpL0t7/9TZIZiAzDkI+Pj1asWKE2bdoUSu1wlp+/k+Hh4apYsaJCQ0Md+2rVqiXDMHTgwAFVr169QGtGVvnpx/Hjx+uuu+7S008/LUmqW7eugoOD1aJFC7366qv89tJNFKWsw8jsDfj5+SkmJkYJCQlO+xMSEtS8efNsj2nWrFmW9itWrFCjRo3k6+tbYLUiZ/npR8kckR0wYIA+/fRT5nMVAXntx5CQEG3fvl1bt251bEOHDtVtt92mrVu3qkmTJoVVOq6Rn7+Td911lw4dOqSzZ8869v3666/y8vJSREREgdaL7OWnH8+fPy8vL+f44e3tLenKyB6KviKVdQr9kjM3ZF92ZPr06cbOnTuNkSNHGsHBwca+ffsMwzCMZ5991nj44Ycd7e3LVYwaNcrYuXOnMX36dJbmKgLy2o+ffvqp4ePjY0yePNlITU11bCdPnrTqI8DIez9ei9UMio689uWZM2eMiIgIo3v37saOHTuMNWvWGNWrVzeGDBli1UeAkfd+nDlzpuHj42NMmTLF2LNnj/Htt98ajRo1Mho3bmzVR4Bh/v1KSkoykpKSDEnGxIkTjaSkJMcSa0U56xBmc2ny5MlGVFSU4efnZzRs2NBYs2aN47X+/fsbrVq1cmq/evVqo0GDBoafn58RHR1tTJ06tZArRnby0o+tWrUyJGXZ+vfvX/iFw0le/z5ejTBbtOS1L3ft2mXce++9RmBgoBEREWGMHj3aOH/+fCFXjWvltR/fffddo3bt2kZgYKARHh5u9O3b1zhw4EAhV42rrVq16rr/zyvKWcdmGIzpAwAAwD0xZxYAAABuizALAAAAt0WYBQAAgNsizAIAAMBtEWYBAADgtgizAAAAcFuEWQAAALgtwiwAAADcFmEWADxAdHS0Jk2a5PK2AFDUcQcwAHCxAQMG6L///a8kycfHR5GRkYqNjdW4ceMUHBxcIO/5xx9/KDg4WEFBQS5tCwBFnY/VBQCAJ/rrX/+qmTNnKi0tTYmJiRoyZIjOnTunqVOnOrVLS0uTr6/vTb9fmTJlCqQtABR1TDMAgALg7++v8uXLKzIyUn369FHfvn21aNEijR07VvXr19eMGTNUpUoV+fv7yzAMnTp1So8++qjKli2rkJAQtWnTRj/++KPTORcvXqxGjRopICBAYWFhio2Ndbx27dSBsWPHqlKlSvL391eFChU0fPjwHNumpKSoW7duKlGihEJCQtSjRw8dOXLE6Vz169fXrFmzFB0drdDQUPXq1Utnzpxx/RcHAHlEmAWAQhAYGKi0tDRJ0m+//aa5c+dq/vz52rp1qySpU6dOOnz4sOLj47VlyxY1bNhQ99xzj06cOCFJWrZsmWJjY9WpUyclJSVp5cqVatSoUbbvNW/ePP373//W+++/r927d2vRokW64447sm1rGIbuu+8+nThxQmvWrFFCQoL27Nmjnj17OrXbs2ePFi1apKVLl2rp0qVas2aN3njjDRd9OwCQf0wzAIACtnHjRn366ae65557JEmXL1/WrFmzHL/u/+abb7R9+3YdPXpU/v7+kqS33npLixYt0rx58/Too4/qtddeU69evTRu3DjHeevVq5ft+6WkpKh8+fK699575evrq0qVKqlx48bZtv3666+1bds2JScnKzIyUpI0a9Ys3X777dq0aZPuvPNOSVJmZqbi4uJUsmRJSdLDDz+slStX6rXXXnPBNwQA+cfILAAUgKVLl6pEiRIKCAhQs2bN1LJlS7333nuSpKioKKd5q1u2bNHZs2dVunRplShRwrElJydrz549kqStW7c6wvCNPPjgg7pw4YKqVKmiRx55RAsXLlR6enq2bXft2qXIyEhHkJWk2rVrq1SpUtq1a5djX3R0tCPISlJ4eLiOHj2a+y8EAAoII7MAUABat26tqVOnytfXVxUqVHC6yOvaFQ0yMzMVHh6u1atXZzlPqVKlJJnTFHIrMjJSv/zyixISEvT1119r2LBh+te//qU1a9ZkudjMMAzZbLYs57h2/7XH2Ww2ZWZm5romACgojMwCQAEIDg5WtWrVFBUVdcPVCho2bKjDhw/Lx8dH1apVc9rCwsIkSXXr1tXKlStz/f6BgYHq2rWr3n33Xa1evVrr16/X9u3bs7SrXbu2UlJStH//fse+nTt36tSpU6pVq1au3w8ArMLILABY7N5771WzZs1033336c0339Rtt92mQ4cOKT4+Xvfdd58aNWqkl156Sffcc4+qVq2qXr16KT09XV9++aWeeeaZLOeLi4tTRkaGmjRpoqCgIM2aNUuBgYGKiorK9r3r1q2rvn37atKkSUpPT9ewYcPUqlWrHC8wA4CihJFZALCYzWZTfHy8WrZsqUGDBqlGjRrq1auX9u3bp3LlykmS7r77bn3++edavHix6tevrzZt2mjDhg3Znq9UqVL64IMPdNdddzlGdJcsWaLSpUtn+96LFi3SLbfcopYtW+ree+9VlSpVNGfOnAL9zADgKtwBDAAAAG6LkVkAAAC4LcIsAAAA3BZhFgAAAG6LMAsAAAC3RZgFAACA2yLMAgAAwG0RZgEAAOC2CLMAAABwW4RZAAAAuC3CLAAAANwWYRYAAABu6/8BzNyNyqyIWLQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_data(csv_file_path):\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    \n",
    "    if 'precision' not in df.columns or 'recall' not in df.columns:\n",
    "        raise ValueError(\"CSV file must contain 'precision' and 'recall' columns\")\n",
    "\n",
    "    precision = df['precision']\n",
    "    recall = df['recall']\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(precision, recall, marker='o', linestyle='-', color='b', label=\"Precision-Recall Curve\")\n",
    "\n",
    "    plt.xlabel(\"Precision\")\n",
    "    plt.ylabel(\"Recall\")\n",
    "    plt.title(\"Precision-Recall Curve\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "csv_file = \"data_file.csv\"\n",
    "with open(csv_file, \"w\", newline=\"\") as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerow([\"precision\", \"recall\"])  # Write header\n",
    "    w.writerows([\n",
    "        [0.013, 0.951],\n",
    "        [0.376, 0.851],\n",
    "        [0.441, 0.839],\n",
    "        [0.570, 0.758],\n",
    "        [0.635, 0.674],\n",
    "        [0.721, 0.604],\n",
    "        [0.837, 0.531],\n",
    "        [0.860, 0.453],\n",
    "        [0.962, 0.348],\n",
    "        [0.982, 0.273],\n",
    "        [1.000, 0.000]\n",
    "    ])\n",
    "plot_data(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4dc37708-f41a-431f-ac35-38e19826c6f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mGenerator\u001b[39;00m(\u001b[43mnn\u001b[49m\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(100, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 784),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.model(x)\n",
    "        output = output.view(x.size(0), 1, 28, 28)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3e85711-df5e-4334-be2c-e7aa1f601c0d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# You can copy this code to your personal pipeline project or execute it here.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_gan\u001b[39m(batch_size: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m, num_epochs: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m, device: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m      3\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m    The method trains a Generative Adversarial Network and is based on:\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m    https://realpython.com/generative-adversarial-networks/\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03m    >>> train_gan(batch_size=32, num_epochs=100)\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# Add/adjust code.\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "# You can copy this code to your personal pipeline project or execute it here.\n",
    "def train_gan(batch_size: int = 32, num_epochs: int = 100, device: str = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"):\n",
    "    \"\"\"\n",
    "    The method trains a Generative Adversarial Network and is based on:\n",
    "    https://realpython.com/generative-adversarial-networks/\n",
    "\n",
    "    The Generator network tries to generate convincing images of handwritten digits.\n",
    "    The Discriminator needs to detect if the image was created by the Generater or if the image is a real image from\n",
    "    a known dataset (MNIST).\n",
    "    If both the Generator and the Discriminator are optimized, the Generator is able to create images that are difficult\n",
    "    to distinguish from real images. This is goal of a GAN.\n",
    "\n",
    "    This code produces the expected results at first attempt at about 50 epochs.\n",
    "\n",
    "    :param batch_size: The number of images to train in one epoch.\n",
    "    :param num_epochs: The number of epochs to train the gan.\n",
    "    :param device: The computing device to use. If CUDA is installed and working then `cuda:0` is chosen\n",
    "        otherwise 'cpu' is chosen. Note: Training a GAN on the CPU is very slow.\n",
    "\n",
    "    **This method is part of a series of debugging exercises.**\n",
    "    **Each Python method of this series contains bug that needs to be found.**\n",
    "\n",
    "    It contains at least two bugs: one structural bug and one cosmetic bug. Both bugs are from the original tutorial.\n",
    "\n",
    "    | ``1   Changing the batch_size from 32 to 64 triggers the structural bug.``\n",
    "    | ``2   Can you also spot the cosmetic bug?``\n",
    "    | ``Note: to fix this bug a thorough understanding of GANs is not necessary.``\n",
    "\n",
    "    Change the batch size to 64 to trigger the bug with message:\n",
    "    ValueError: \"Using a target size (torch.Size([128, 1])) that is different to the input size (torch.Size([96, 1])) is deprecated. Please ensure they have the same size.\"\n",
    "\n",
    "    >>> train_gan(batch_size=32, num_epochs=100)\n",
    "    \"\"\"\n",
    "    # Add/adjust code.\n",
    "\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "    try:\n",
    "        train_set = torchvision.datasets.MNIST(root=\".\", train=True, download=True, transform=transform)\n",
    "    except:\n",
    "        print(\"Failed to download MNIST, retrying with different URL\")\n",
    "        # see: https://github.com/pytorch/vision/blob/master/torchvision/datasets/mnist.py\n",
    "        torchvision.datasets.MNIST.resources = [\n",
    "            ('https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz',\n",
    "             'f68b3c2dcbeaaa9fbdd348bbdeb94873'),\n",
    "            ('https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz',\n",
    "             'd53e105ee54ea40749a09fcbcd1e9432'),\n",
    "            ('https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz',\n",
    "             '9fb629c4189551a2d022fa330f9573f3'),\n",
    "            ('https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz',\n",
    "             'ec29112dd5afa0611ce80d1b7f02629c')\n",
    "        ]\n",
    "        train_set = torchvision.datasets.MNIST(root=\".\", train=True, download=True, transform=transform)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # example data\n",
    "    real_samples, mnist_labels = next(iter(train_loader))\n",
    "\n",
    "    fig = plt.figure()\n",
    "    for i in range(16):\n",
    "        sub = fig.add_subplot(4, 4, 1 + i)\n",
    "        sub.imshow(real_samples[i].reshape(28, 28), cmap=\"gray_r\")\n",
    "        sub.axis('off')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.suptitle(\"Real images\")\n",
    "    display(fig)\n",
    "\n",
    "    time.sleep(5)\n",
    "\n",
    "    # Set up training\n",
    "    discriminator = Discriminator().to(device)\n",
    "    generator = Generator().to(device)\n",
    "    lr = 0.0001\n",
    "    loss_function = nn.BCELoss()\n",
    "    optimizer_discriminator = torch.optim.Adam(discriminator.parameters(), lr=lr)\n",
    "    optimizer_generator = torch.optim.Adam(generator.parameters(), lr=lr)\n",
    "\n",
    "    # train\n",
    "    for epoch in range(num_epochs):\n",
    "        for n, (real_samples, mnist_labels) in enumerate(train_loader):\n",
    "\n",
    "            # Data for training the discriminator\n",
    "            real_samples = real_samples.to(device=device)\n",
    "            real_samples_labels = torch.ones((batch_size, 1)).to(device=device)\n",
    "            latent_space_samples = torch.randn((batch_size, 100)).to(device=device)\n",
    "            generated_samples = generator(latent_space_samples)\n",
    "            generated_samples_labels = torch.zeros((batch_size, 1)).to(device=device)\n",
    "            all_samples = torch.cat((real_samples, generated_samples))\n",
    "            all_samples_labels = torch.cat((real_samples_labels, generated_samples_labels))\n",
    "\n",
    "            # Training the discriminator\n",
    "            discriminator.zero_grad()\n",
    "            output_discriminator = discriminator(all_samples)\n",
    "            loss_discriminator = loss_function(output_discriminator, all_samples_labels)\n",
    "            loss_discriminator.backward()\n",
    "            optimizer_discriminator.step()\n",
    "\n",
    "            # Data for training the generator\n",
    "            latent_space_samples = torch.randn((batch_size, 100)).to(device=device)\n",
    "\n",
    "            # Training the generator\n",
    "            generator.zero_grad()\n",
    "            generated_samples = generator(latent_space_samples)\n",
    "            output_discriminator_generated = discriminator(generated_samples)\n",
    "            loss_generator = loss_function(output_discriminator_generated, real_samples_labels)\n",
    "            loss_generator.backward()\n",
    "            optimizer_generator.step()\n",
    "\n",
    "            # Show loss and samples generated\n",
    "            if n == batch_size - 1:\n",
    "                name = f\"Generate images\\n Epoch: {epoch} Loss D.: {loss_discriminator:.2f} Loss G.: {loss_generator:.2f}\"\n",
    "                generated_samples = generated_samples.detach().cpu().numpy()\n",
    "                fig = plt.figure()\n",
    "                for i in range(16):\n",
    "                    sub = fig.add_subplot(4, 4, 1 + i)\n",
    "                    sub.imshow(generated_samples[i].reshape(28, 28), cmap=\"gray_r\")\n",
    "                    sub.axis('off')\n",
    "                fig.suptitle(name)\n",
    "                fig.tight_layout()\n",
    "                clear_output(wait=False)\n",
    "                display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b4f69fd-8222-4ccd-a818-fb4d412828bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "import time\n",
    "\n",
    "def train_gan(batch_size: int = 32, num_epochs: int = 100, device: str = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"):\n",
    "\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "    train_set = torchvision.datasets.MNIST(root=\".\", train=True, download=True, transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    discriminator = Discriminator().to(device)\n",
    "    generator = Generator().to(device)\n",
    "    loss_function = nn.BCELoss()\n",
    "    optimizer_discriminator = optim.Adam(discriminator.parameters(), lr=0.0001)\n",
    "    optimizer_generator = optim.Adam(generator.parameters(), lr=0.0001)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for n, (real_samples, _) in enumerate(train_loader):\n",
    "            real_batch_size = real_samples.shape[0] \n",
    "            real_samples = real_samples.to(device)\n",
    "            real_samples_labels = torch.ones((real_batch_size, 1)).to(device)\n",
    "\n",
    "            latent_space_samples = torch.randn((real_batch_size, 100)).to(device)\n",
    "            generated_samples = generator(latent_space_samples)\n",
    "            generated_samples_labels = torch.zeros((real_batch_size, 1)).to(device)\n",
    "\n",
    "            all_samples = torch.cat((real_samples, generated_samples))\n",
    "            all_samples_labels = torch.cat((real_samples_labels, generated_samples_labels))\n",
    "\n",
    "            discriminator.zero_grad()\n",
    "            output_discriminator = discriminator(all_samples)\n",
    "            loss_discriminator = loss_function(output_discriminator, all_samples_labels)\n",
    "            loss_discriminator.backward()\n",
    "            optimizer_discriminator.step()\n",
    "\n",
    "            generator.zero_grad()\n",
    "            latent_space_samples = torch.randn((real_batch_size, 100)).to(device)\n",
    "            generated_samples = generator(latent_space_samples)\n",
    "            output_discriminator_generated = discriminator(generated_samples)\n",
    "            loss_generator = loss_function(output_discriminator_generated, real_samples_labels)\n",
    "            loss_generator.backward()\n",
    "            optimizer_generator.step()\n",
    "        if epoch % 10 == 0:  \n",
    "            generated_samples = generated_samples.detach().cpu().numpy()\n",
    "            generated_samples = (generated_samples + 1) / 2  \n",
    "\n",
    "            fig, axes = plt.subplots(4, 4, figsize=(6, 6))\n",
    "            for i, ax in enumerate(axes.flat):\n",
    "                ax.imshow(generated_samples[i].reshape(28, 28), cmap=\"gray_r\")\n",
    "                ax.axis(\"off\")\n",
    "\n",
    "            fig.suptitle(f\"Epoch {epoch}: D Loss = {loss_discriminator:.4f}, G Loss = {loss_generator:.4f}\")\n",
    "            clear_output(wait=True)\n",
    "            display(fig)\n",
    "            time.sleep(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e5ad0cbb-ee90-4a42-a51d-84e954b3c8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in links: /usr/share/pip-wheels\n",
      "Collecting torch\n",
      "  Downloading torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.21.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.6.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/anaconda-2024.02-py310/lib/python3.10/site-packages (from torch) (3.13.1)\n",
      "Collecting typing-extensions>=4.10.0 (from torch)\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: networkx in /opt/conda/envs/anaconda-2024.02-py310/lib/python3.10/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/envs/anaconda-2024.02-py310/lib/python3.10/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/conda/envs/anaconda-2024.02-py310/lib/python3.10/site-packages (from torch) (2023.10.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch)\n",
      "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch)\n",
      "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.2.0 (from torch)\n",
      "  Downloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/envs/anaconda-2024.02-py310/lib/python3.10/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/anaconda-2024.02-py310/lib/python3.10/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/envs/anaconda-2024.02-py310/lib/python3.10/site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/envs/anaconda-2024.02-py310/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Downloading torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl (766.7 MB)\n",
      "\u001b[2K   \u001b[38;5;70m\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[38;5;70m\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[38;5;70m\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[38;5;70m\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[38;5;70m\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[38;5;70m\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[38;5;70m\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[38;5;70m\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[38;5;70m\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[38;5;70m\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
      "\u001b[2K   \u001b[38;5;70m\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "\u001b[2K   \u001b[38;5;197m\u001b[0m\u001b[38;5;197m\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m290.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: Could not install packages due to an OSError: [Errno 122] Disk quota exceeded\n",
      "\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0fc559dc-1a2d-4a4a-bd87-bbc0ae833ebb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39m__version__)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d9d3fa15-257a-4d76-b762-664b411a1154",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "import time\n",
    "\n",
    "def train_gan(batch_size: int = 32, num_epochs: int = 100, device: str = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"):\n",
    "\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "    train_set = torchvision.datasets.MNIST(root=\".\", train=True, download=True, transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    discriminator = Discriminator().to(device)\n",
    "    generator = Generator().to(device)\n",
    "    loss_function = nn.BCELoss()\n",
    "    optimizer_discriminator = optim.Adam(discriminator.parameters(), lr=0.0001)\n",
    "    optimizer_generator = optim.Adam(generator.parameters(), lr=0.0001)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for n, (real_samples, _) in enumerate(train_loader):\n",
    "            real_batch_size = real_samples.shape[0] \n",
    "            real_samples = real_samples.to(device)\n",
    "            real_samples_labels = torch.ones((real_batch_size, 1)).to(device)\n",
    "\n",
    "            latent_space_samples = torch.randn((real_batch_size, 100)).to(device)\n",
    "            generated_samples = generator(latent_space_samples)\n",
    "            generated_samples_labels = torch.zeros((real_batch_size, 1)).to(device)\n",
    "\n",
    "            all_samples = torch.cat((real_samples, generated_samples))\n",
    "            all_samples_labels = torch.cat((real_samples_labels, generated_samples_labels))\n",
    "\n",
    "            discriminator.zero_grad()\n",
    "            output_discriminator = discriminator(all_samples)\n",
    "            loss_discriminator = loss_function(output_discriminator, all_samples_labels)\n",
    "            loss_discriminator.backward()\n",
    "            optimizer_discriminator.step()\n",
    "\n",
    "            generator.zero_grad()\n",
    "            latent_space_samples = torch.randn((real_batch_size, 100)).to(device)\n",
    "            generated_samples = generator(latent_space_samples)\n",
    "            output_discriminator_generated = discriminator(generated_samples)\n",
    "            loss_generator = loss_function(output_discriminator_generated, real_samples_labels)\n",
    "            loss_generator.backward()\n",
    "            optimizer_generator.step()\n",
    "        if epoch % 10 == 0:  \n",
    "            generated_samples = generated_samples.detach().cpu().numpy()\n",
    "            generated_samples = (generated_samples + 1) / 2  \n",
    "\n",
    "            fig, axes = plt.subplots(4, 4, figsize=(6, 6))\n",
    "            for i, ax in enumerate(axes.flat):\n",
    "                ax.imshow(generated_samples[i].reshape(28, 28), cmap=\"gray_r\")\n",
    "                ax.axis(\"off\")\n",
    "\n",
    "            fig.suptitle(f\"Epoch {epoch}: D Loss = {loss_discriminator:.4f}, G Loss = {loss_generator:.4f}\")\n",
    "            clear_output(wait=True)\n",
    "            display(fig)\n",
    "            time.sleep(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "62f4b848-ab04-4155-b577-e3cf9205b530",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "import time\n",
    "\n",
    "def train_gan(batch_size: int = 32, num_epochs: int = 100, device: str = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"):\n",
    "\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "    train_set = torchvision.datasets.MNIST(root=\".\", train=True, download=True, transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    discriminator = Discriminator().to(device)\n",
    "    generator = Generator().to(device)\n",
    "    loss_function = nn.BCELoss()\n",
    "    optimizer_discriminator = optim.Adam(discriminator.parameters(), lr=0.0001)\n",
    "    optimizer_generator = optim.Adam(generator.parameters(), lr=0.0001)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for n, (real_samples, _) in enumerate(train_loader):\n",
    "            real_batch_size = real_samples.shape[0] \n",
    "            real_samples = real_samples.to(device)\n",
    "            real_samples_labels = torch.ones((real_batch_size, 1)).to(device)\n",
    "\n",
    "            latent_space_samples = torch.randn((real_batch_size, 100)).to(device)\n",
    "            generated_samples = generator(latent_space_samples)\n",
    "            generated_samples_labels = torch.zeros((real_batch_size, 1)).to(device)\n",
    "\n",
    "            all_samples = torch.cat((real_samples, generated_samples))\n",
    "            all_samples_labels = torch.cat((real_samples_labels, generated_samples_labels))\n",
    "\n",
    "            discriminator.zero_grad()\n",
    "            output_discriminator = discriminator(all_samples)\n",
    "            loss_discriminator = loss_function(output_discriminator, all_samples_labels)\n",
    "            loss_discriminator.backward()\n",
    "            optimizer_discriminator.step()\n",
    "\n",
    "            generator.zero_grad()\n",
    "            latent_space_samples = torch.randn((real_batch_size, 100)).to(device)\n",
    "            generated_samples = generator(latent_space_samples)\n",
    "            output_discriminator_generated = discriminator(generated_samples)\n",
    "            loss_generator = loss_function(output_discriminator_generated, real_samples_labels)\n",
    "            loss_generator.backward()\n",
    "            optimizer_generator.step()\n",
    "        if epoch % 10 == 0:  \n",
    "            generated_samples = generated_samples.detach().cpu().numpy()\n",
    "            generated_samples = (generated_samples + 1) / 2  \n",
    "\n",
    "            fig, axes = plt.subplots(4, 4, figsize=(6, 6))\n",
    "            for i, ax in enumerate(axes.flat):\n",
    "                ax.imshow(generated_samples[i].reshape(28, 28), cmap=\"gray_r\")\n",
    "                ax.axis(\"off\")\n",
    "\n",
    "            fig.suptitle(f\"Epoch {epoch}: D Loss = {loss_discriminator:.4f}, G Loss = {loss_generator:.4f}\")\n",
    "            clear_output(wait=True)\n",
    "            display(fig)\n",
    "            time.sleep(1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5c8e298c-c979-4843-94ca-f9878e5119ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Set,Tuple, List\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from typing import Set,Tuple, List\n",
    "import torch\n",
    "import torch.utils\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "NoneType = type(None)\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision.models import vgg11\n",
    "from torchvision.models import mobilenet_v2\n",
    "import torchvision.transforms as transforms\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3326e4c3-cee4-4e4b-8e5f-3f20a9dabd58",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39m__version__)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d4b38986-ebc1-4b65-bcfc-810f3906da98",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (609037931.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[38], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    python -c \"import torch; print(torch.__version__)\"\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "python -c \"import torch; print(torch.__version__)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0e216102-cda8-482a-8dae-add5a9c683af",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "import time\n",
    "\n",
    "def train_gan(batch_size: int = 32, num_epochs: int = 100, device: str = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"):\n",
    "\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "    train_set = torchvision.datasets.MNIST(root=\".\", train=True, download=True, transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    discriminator = Discriminator().to(device)\n",
    "    generator = Generator().to(device)\n",
    "    loss_function = nn.BCELoss()\n",
    "    optimizer_discriminator = optim.Adam(discriminator.parameters(), lr=0.0001)\n",
    "    optimizer_generator = optim.Adam(generator.parameters(), lr=0.0001)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for n, (real_samples, _) in enumerate(train_loader):\n",
    "            real_batch_size = real_samples.shape[0] \n",
    "            real_samples = real_samples.to(device)\n",
    "            real_samples_labels = torch.ones((real_batch_size, 1)).to(device)\n",
    "\n",
    "            latent_space_samples = torch.randn((real_batch_size, 100)).to(device)\n",
    "            generated_samples = generator(latent_space_samples)\n",
    "            generated_samples_labels = torch.zeros((real_batch_size, 1)).to(device)\n",
    "\n",
    "            all_samples = torch.cat((real_samples, generated_samples))\n",
    "            all_samples_labels = torch.cat((real_samples_labels, generated_samples_labels))\n",
    "\n",
    "            discriminator.zero_grad()\n",
    "            output_discriminator = discriminator(all_samples)\n",
    "            loss_discriminator = loss_function(output_discriminator, all_samples_labels)\n",
    "            loss_discriminator.backward()\n",
    "            optimizer_discriminator.step()\n",
    "\n",
    "            generator.zero_grad()\n",
    "            latent_space_samples = torch.randn((real_batch_size, 100)).to(device)\n",
    "            generated_samples = generator(latent_space_samples)\n",
    "            output_discriminator_generated = discriminator(generated_samples)\n",
    "            loss_generator = loss_function(output_discriminator_generated, real_samples_labels)\n",
    "            loss_generator.backward()\n",
    "            optimizer_generator.step()\n",
    "        if epoch % 10 == 0:  \n",
    "            generated_samples = generated_samples.detach().cpu().numpy()\n",
    "            generated_samples = (generated_samples + 1) / 2  \n",
    "\n",
    "            fig, axes = plt.subplots(4, 4, figsize=(6, 6))\n",
    "            for i, ax in enumerate(axes.flat):\n",
    "                ax.imshow(generated_samples[i].reshape(28, 28), cmap=\"gray_r\")\n",
    "                ax.axis(\"off\")\n",
    "\n",
    "            fig.suptitle(f\"Epoch {epoch}: D Loss = {loss_discriminator:.4f}, G Loss = {loss_generator:.4f}\")\n",
    "            clear_output(wait=True)\n",
    "            display(fig)\n",
    "            time.sleep(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e3a3cc23-4c2e-4338-bb58-2fbcab64e0f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "def train_gan(batch_size: int = 32, num_epochs: int = 100, device: str = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"):\n",
    "\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "    train_set = torchvision.datasets.MNIST(root=\".\", train=True, download=True, transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    discriminator = Discriminator().to(device)\n",
    "    generator = Generator().to(device)\n",
    "    loss_function = nn.BCELoss()\n",
    "    optimizer_discriminator = optim.Adam(discriminator.parameters(), lr=0.0001)\n",
    "    optimizer_generator = optim.Adam(generator.parameters(), lr=0.0001)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for n, (real_samples, _) in enumerate(train_loader):\n",
    "            real_batch_size = real_samples.shape[0] \n",
    "            real_samples = real_samples.to(device)\n",
    "            real_samples_labels = torch.ones((real_batch_size, 1)).to(device)\n",
    "\n",
    "            latent_space_samples = torch.randn((real_batch_size, 100)).to(device)\n",
    "            generated_samples = generator(latent_space_samples)\n",
    "            generated_samples_labels = torch.zeros((real_batch_size, 1)).to(device)\n",
    "\n",
    "            all_samples = torch.cat((real_samples, generated_samples))\n",
    "            all_samples_labels = torch.cat((real_samples_labels, generated_samples_labels))\n",
    "\n",
    "            discriminator.zero_grad()\n",
    "            output_discriminator = discriminator(all_samples)\n",
    "            loss_discriminator = loss_function(output_discriminator, all_samples_labels)\n",
    "            loss_discriminator.backward()\n",
    "            optimizer_discriminator.step()\n",
    "\n",
    "            generator.zero_grad()\n",
    "            latent_space_samples = torch.randn((real_batch_size, 100)).to(device)\n",
    "            generated_samples = generator(latent_space_samples)\n",
    "            output_discriminator_generated = discriminator(generated_samples)\n",
    "            loss_generator = loss_function(output_discriminator_generated, real_samples_labels)\n",
    "            loss_generator.backward()\n",
    "            optimizer_generator.step()\n",
    "        if epoch % 10 == 0:  \n",
    "            generated_samples = generated_samples.detach().cpu().numpy()\n",
    "            generated_samples = (generated_samples + 1) / 2  \n",
    "\n",
    "            fig, axes = plt.subplots(4, 4, figsize=(6, 6))\n",
    "            for i, ax in enumerate(axes.flat):\n",
    "                ax.imshow(generated_samples[i].reshape(28, 28), cmap=\"gray_r\")\n",
    "                ax.axis(\"off\")\n",
    "\n",
    "            fig.suptitle(f\"Epoch {epoch}: D Loss = {loss_discriminator:.4f}, G Loss = {loss_generator:.4f}\")\n",
    "            clear_output(wait=True)\n",
    "            display(fig)\n",
    "            time.sleep(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c546a85c-c4a8-42fa-a49a-5219c81c3da2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-2024.02-py310",
   "language": "python",
   "name": "conda-env-anaconda-2024.02-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
